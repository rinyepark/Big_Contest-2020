{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data: augment_24group_1620.csv필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_lstm_train_X = pd.read_csv(\"lstmPCT/PCT_lstm_final_train_X.csv\")\n",
    "PCT_lstm_train_y = pd.read_csv(\"lstmPCT/PCT_lstm_final_train_y.csv\")\n",
    "\n",
    "PCT_lstm_test_X = pd.read_csv(\"lstmPCT/PCT_lstm_final_test_X.csv\")\n",
    "PCT_lstm_test_y = pd.read_csv(\"lstmPCT/PCT_lstm_final_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = list(PCT_lstm_train_X.T_ID.unique())\n",
    "year = list(PCT_lstm_train_y.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) input shape로 변경 (row, timestep=2, feature)\n",
    "\n",
    "ex) \n",
    "timestep = 2\n",
    "\n",
    "* X_train_v 구성예시: [[1 ~ 24경기 데이터, 25 ~ 48경기 데이터], [49 ~ 72경기 데이터, 73 ~ 96경기 데이터] ]  \n",
    "X_train_v.shape >> (2,2*x)             # x: 각 24group에 대한 변수 개수\n",
    "* y_train_v 구성예시: 97 ~ 120 경기 승률\n",
    "\n",
    "=> reshape\n",
    "\n",
    "* X_train_v.shape >> (2,2,x)  # row, timestep, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성(LSTM)\n",
    "- optimizer: RMSprop -> lr(learning rate) 조절\n",
    "- LSTM: 모델이 계속 동일한 결과값이 나올 때, input 뉴런 개수를 늘려야 한다는 글을 읽고 계속 input 노드 개수를 바꿔주면서 모델 생성중\n",
    "- loss: MSE\n",
    "\n",
    "- early_stop: patience를 크게하면 과적합 되는 경우가 있어서 최대한 작게 설정해둠\n",
    "- batch_size: 모델이 계속 동일한 결과값이 나올 때, 데이터가 적어 batch size를 줄여보라는 글을 읽고 1로 설정해둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 17ms/sample - loss: 0.1379 - mae: 0.1871\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0169 - mae: 0.1058\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0173 - mae: 0.1082\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 1ms/sample - loss: 0.0179 - mae: 0.1056\n",
      "Epoch 00004: early stopping\n",
      "HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 14ms/sample - loss: 0.1836 - mae: 0.1974\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0151 - mae: 0.1035\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0144 - mae: 0.0992\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0130 - mae: 0.0954\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0137 - mae: 0.0943\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0126 - mae: 0.0912\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0140 - mae: 0.0942\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0120 - mae: 0.0916\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0102 - mae: 0.0817\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0093 - mae: 0.0776\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0132 - mae: 0.0937\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0110 - mae: 0.0841\n",
      "Epoch 00012: early stopping\n",
      "NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 2s 13ms/sample - loss: 0.1479 - mae: 0.1885\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0087 - mae: 0.0719\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0083 - mae: 0.0692\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0084 - mae: 0.0720\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0092 - mae: 0.0748\n",
      "Epoch 00005: early stopping\n",
      "HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 13ms/sample - loss: 0.1960 - mae: 0.1929\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0113 - mae: 0.0879\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0103 - mae: 0.0827\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0107 - mae: 0.0852\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0107 - mae: 0.0854\n",
      "Epoch 00005: early stopping\n",
      "SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 2s 13ms/sample - loss: 0.1881 - mae: 0.2076\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0159 - mae: 0.1039\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0147 - mae: 0.0963\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0143 - mae: 0.0975\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0128 - mae: 0.0893\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0107 - mae: 0.0836\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0090 - mae: 0.0739\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0068 - mae: 0.0675\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0065 - mae: 0.0648\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0067 - mae: 0.0656\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0054 - mae: 0.0623\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0066 - mae: 0.0659\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0054 - mae: 0.0589\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0044 - mae: 0.0540\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0053 - mae: 0.0561\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0049 - mae: 0.0565\n",
      "Epoch 00016: early stopping\n",
      "KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 3s 14ms/sample - loss: 0.2360 - mae: 0.2184\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0276 - mae: 0.1369\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0243 - mae: 0.1302 0s - loss: 0.0260 - mae: 0\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0237 - mae: 0.1267\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 3ms/sample - loss: 0.0193 - mae: 0.1154\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 3ms/sample - loss: 0.0167 - mae: 0.1042\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 3ms/sample - loss: 0.0150 - mae: 0.1027\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0111 - mae: 0.0851\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0083 - mae: 0.0738\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0067 - mae: 0.0669\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0073 - mae: 0.0691\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0087 - mae: 0.0753\n",
      "Epoch 00012: early stopping\n",
      "WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 17ms/sample - loss: 0.1591 - mae: 0.1561\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0058 - mae: 0.0639\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0054 - mae: 0.0611\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0048 - mae: 0.0580\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0051 - mae: 0.0567\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0045 - mae: 0.0544\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0044 - mae: 0.0553\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 3ms/sample - loss: 0.0038 - mae: 0.0502\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0040 - mae: 0.0510\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0041 - mae: 0.0528\n",
      "Epoch 00010: early stopping\n",
      "LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 16ms/sample - loss: 0.1602 - mae: 0.1875\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0108 - mae: 0.0852\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0092 - mae: 0.0780\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0089 - mae: 0.0780\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0081 - mae: 0.0744\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0087 - mae: 0.0733\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0072 - mae: 0.0666\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0064 - mae: 0.0623\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0056 - mae: 0.0601\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0054 - mae: 0.0564\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0060 - mae: 0.0604\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0059 - mae: 0.0597\n",
      "Epoch 00012: early stopping\n",
      "SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 16ms/sample - loss: 0.1778 - mae: 0.1866\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 3ms/sample - loss: 0.0099 - mae: 0.0799\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0100 - mae: 0.0791\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0092 - mae: 0.0766\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0096 - mae: 0.0795\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0091 - mae: 0.0752\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0083 - mae: 0.0729\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0109 - mae: 0.0834\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0075 - mae: 0.0690\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0078 - mae: 0.0685\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0068 - mae: 0.0658\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0068 - mae: 0.0678\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0089 - mae: 0.0768\n",
      "Epoch 00013: early stopping\n",
      "OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               63200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 63,301\n",
      "Trainable params: 63,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 196 samples\n",
      "Epoch 1/100\n",
      "196/196 [==============================] - 3s 15ms/sample - loss: 0.1191 - mae: 0.1727\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0146 - mae: 0.0972\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0147 - mae: 0.0990\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 0s 3ms/sample - loss: 0.0143 - mae: 0.0952\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0144 - mae: 0.0980\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 0s 2ms/sample - loss: 0.0154 - mae: 0.1012\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms0.5'])\n",
    "\n",
    "idx = 0\n",
    "\n",
    "tmp1 = PCT_lstm_train_X\n",
    "tmp2 = PCT_lstm_train_y\n",
    "tmp3 = PCT_lstm_test_X\n",
    "tmp4 = PCT_lstm_test_y\n",
    "\n",
    "for t in team:\n",
    "    name = '{}'.format(t)\n",
    "    print(name,\"=======================================\")\n",
    "\n",
    "    X_train = tmp1[tmp1[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "    y_train = tmp2[tmp2[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "    X_test = tmp3[tmp3[\"T_ID\"] == t].drop([\"T_ID\",'YEAR'],axis=1)\n",
    "    y_test = tmp4[tmp4[\"T_ID\"] == t].drop([\"T_ID\",'YEAR'],axis=1)\n",
    "\n",
    "    X_train_v = X_train.values\n",
    "    y_train_v = y_train.values\n",
    "\n",
    "    X_test_v = X_test.values\n",
    "    y_test_v = y_test.values\n",
    "\n",
    "    X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,X_train_v.shape[1]//2)\n",
    "    X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,X_test_v.shape[1]//2)\n",
    "\n",
    "    ## model\n",
    "    K.clear_session() \n",
    "\n",
    "    model = Sequential()\n",
    "    optimizer = Adam(lr=0.01)\n",
    "#         optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "    model.add(LSTM(100,input_shape = (2,X_train_v.shape[1]//2))) # (timestep, feature)\n",
    "    model.add(Dense(1)) # output = 1\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "#         hist1 = model.fit(X_train_t, y_train_v, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "    hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "              batch_size=2, verbose=1, callbacks=[early_stop])\n",
    "    ##\n",
    "\n",
    "    model_dict[name] = model\n",
    "    hist_dict[name] = hist1\n",
    "    \n",
    "    \n",
    "    year = 2016\n",
    "    for tt in range(len(X_test_t)):\n",
    "        ttmp = X_test_t[tt].reshape(1,X_test_t[tt].shape[0],X_test_t[tt].shape[1])\n",
    "        y_pred = model.predict(ttmp)\n",
    "        rms = sqrt(mean_squared_error(y_test_v[tt], y_pred))\n",
    "        rms05 = sqrt(mean_squared_error(y_test_v[tt], [0.5]))\n",
    "    #     rms_avg = sqrt(mean_squared_error(y_test_v,[y_train.mean()[0]]))\n",
    "\n",
    "\n",
    "        test_pred_df.loc[idx,:] = [year,t,y_test_v[tt].reshape(-1)[0],y_pred.reshape(-1)[0],\n",
    "                                  X_test.loc[X_test.index[tt],[\"shift_PCT_1\"]][0],\n",
    "                                  X_test.loc[X_test.index[tt],[\"shift_PCT_2\"]][0], rms,rms05]\n",
    "        year += 1\n",
    "        idx += 1\n",
    "\n",
    "test_pred_df[['y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms0.5']] = test_pred_df[['y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms0.5']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08037503385826161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "tmp = test_pred_df.copy()\n",
    "# tmp['half']= 0.5\n",
    "r2_y_predict = r2_score(tmp['y'], tmp['y_pred'])\n",
    "r2_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.492391</td>\n",
       "      <td>0.497217</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.075725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.498370</td>\n",
       "      <td>0.485499</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.076630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.493422</td>\n",
       "      <td>0.500362</td>\n",
       "      <td>0.497480</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.071377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.505072</td>\n",
       "      <td>0.509464</td>\n",
       "      <td>0.508152</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.105072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_PCT_1  shift_PCT_2       rms    rms0.5\n",
       "YEAR                                                                  \n",
       "2016  0.492391  0.497217     0.504167     0.508514  0.084939  0.075725\n",
       "2017  0.498370  0.485499     0.491848     0.521937  0.095652  0.076630\n",
       "2018  0.507971  0.493422     0.500362     0.497480  0.050633  0.071377\n",
       "2019  0.505072  0.509464     0.508152     0.495290  0.115817  0.105072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred_df.sort_values(by = [\"YEAR\",\"T_ID\"]).to_csv(\"PCT_t2_noseason.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014882024328722784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred_df['y'],test_pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.492391</td>\n",
       "      <td>0.510814</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.075725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.498370</td>\n",
       "      <td>0.488735</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.105351</td>\n",
       "      <td>0.076630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.511459</td>\n",
       "      <td>0.500362</td>\n",
       "      <td>0.497480</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>0.071377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.505072</td>\n",
       "      <td>0.520403</td>\n",
       "      <td>0.508152</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.105072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_PCT_1  shift_PCT_2       rms    rms0.5\n",
       "YEAR                                                                  \n",
       "2016  0.492391  0.510814     0.504167     0.508514  0.070072  0.075725\n",
       "2017  0.498370  0.488735     0.491848     0.521937  0.105351  0.076630\n",
       "2018  0.507971  0.511459     0.500362     0.497480  0.042255  0.071377\n",
       "2019  0.505072  0.520403     0.508152     0.495290  0.121830  0.105072"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.650341</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.041645</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.505163</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.464049</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.047382</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.497537</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044129</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.465625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.472319</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.037537</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424813</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.435061</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.148272</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.460554</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.104664</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.044526</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.457226</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.467660</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.097557</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.467538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.468825</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.514771</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.026896</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482599</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.017401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541792</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.083459</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.471304</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.153696</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.510155</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.698592</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.323592</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.335393</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.292667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.207333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.392325</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.422155</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.119511</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.537834</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.162834</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.556641</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.208815</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.516866</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677138</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.565464</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.065464</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.558520</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.108147</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.599712</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.446556</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.238223</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536140</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.036140</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.553155</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.161850</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.554951</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.033212</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.530183</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.113516</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.547459</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.119208</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.553282</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.030052</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.679719</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.054719</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.546548</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.105626</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred  shift_PCT_1  shift_PCT_2       rms  \\\n",
       "0   2016   LG  0.608696  0.650341     0.583333     0.458333  0.041645   \n",
       "1   2017   LG  0.434783  0.505163     0.304348     0.652174  0.070380   \n",
       "2   2018   LG  0.416667  0.464049     0.291667     0.478261  0.047382   \n",
       "3   2019   LG  0.541667  0.497537     0.541667     0.500000  0.044129   \n",
       "4   2016   HH  0.500000  0.465625     0.500000     0.608696  0.034375   \n",
       "5   2017   HH  0.434783  0.472319     0.541667     0.333333  0.037537   \n",
       "6   2018   HH  0.500000  0.424813     0.416667     0.583333  0.075187   \n",
       "7   2019   HH  0.583333  0.435061     0.375000     0.250000  0.148272   \n",
       "8   2016   NC  0.565217  0.460554     0.500000     0.541667  0.104664   \n",
       "9   2017   NC  0.500000  0.455474     0.458333     0.541667  0.044526   \n",
       "10  2018   NC  0.416667  0.457226     0.521739     0.416667  0.040559   \n",
       "11  2019   NC  0.565217  0.467660     0.541667     0.478261  0.097557   \n",
       "12  2016   HT  0.458333  0.467538     0.500000     0.583333  0.009205   \n",
       "13  2017   HT  0.500000  0.468825     0.500000     0.782609  0.031175   \n",
       "14  2018   HT  0.541667  0.514771     0.541667     0.375000  0.026896   \n",
       "15  2019   HT  0.500000  0.482599     0.478261     0.416667  0.017401   \n",
       "16  2016   SK  0.458333  0.541792     0.458333     0.458333  0.083459   \n",
       "17  2017   SK  0.625000  0.471304     0.458333     0.416667  0.153696   \n",
       "18  2018   SK  0.458333  0.510155     0.500000     0.666667  0.051822   \n",
       "19  2019   SK  0.375000  0.698592     0.625000     0.708333  0.323592   \n",
       "20  2016   KT  0.291667  0.335393     0.333333     0.375000  0.043726   \n",
       "21  2017   KT  0.500000  0.292667     0.333333     0.166667  0.207333   \n",
       "22  2018   KT  0.391304  0.392325     0.416667     0.545455  0.001020   \n",
       "23  2019   KT  0.541667  0.422155     0.521739     0.652174  0.119511   \n",
       "24  2016   WO  0.375000  0.537834     0.625000     0.666667  0.162834   \n",
       "25  2017   WO  0.347826  0.556641     0.500000     0.541667  0.208815   \n",
       "26  2018   WO  0.541667  0.516866     0.666667     0.458333  0.024800   \n",
       "27  2019   WO  0.666667  0.677138     0.565217     0.708333  0.010471   \n",
       "28  2016   LT  0.500000  0.565464     0.375000     0.500000  0.065464   \n",
       "29  2017   LT  0.666667  0.558520     0.750000     0.590909  0.108147   \n",
       "30  2018   LT  0.666667  0.599712     0.458333     0.347826  0.066955   \n",
       "31  2019   LT  0.208333  0.446556     0.391304     0.304348  0.238223   \n",
       "32  2016   SS  0.500000  0.536140     0.500000     0.434783  0.036140   \n",
       "33  2017   SS  0.391304  0.553155     0.333333     0.454545  0.161850   \n",
       "34  2018   SS  0.521739  0.554951     0.565217     0.478261  0.033212   \n",
       "35  2019   SS  0.416667  0.530183     0.375000     0.434783  0.113516   \n",
       "36  2016   OB  0.666667  0.547459     0.666667     0.458333  0.119208   \n",
       "37  2017   OB  0.583333  0.553282     0.739130     0.739130  0.030052   \n",
       "38  2018   OB  0.625000  0.679719     0.625000     0.625000  0.054719   \n",
       "39  2019   OB  0.652174  0.546548     0.666667     0.500000  0.105626   \n",
       "\n",
       "      rms0.5  \n",
       "0   0.108696  \n",
       "1   0.065217  \n",
       "2   0.083333  \n",
       "3   0.041667  \n",
       "4   0.000000  \n",
       "5   0.065217  \n",
       "6   0.000000  \n",
       "7   0.083333  \n",
       "8   0.065217  \n",
       "9   0.000000  \n",
       "10  0.083333  \n",
       "11  0.065217  \n",
       "12  0.041667  \n",
       "13  0.000000  \n",
       "14  0.041667  \n",
       "15  0.000000  \n",
       "16  0.041667  \n",
       "17  0.125000  \n",
       "18  0.041667  \n",
       "19  0.125000  \n",
       "20  0.208333  \n",
       "21  0.000000  \n",
       "22  0.108696  \n",
       "23  0.041667  \n",
       "24  0.125000  \n",
       "25  0.152174  \n",
       "26  0.041667  \n",
       "27  0.166667  \n",
       "28  0.000000  \n",
       "29  0.166667  \n",
       "30  0.166667  \n",
       "31  0.291667  \n",
       "32  0.000000  \n",
       "33  0.108696  \n",
       "34  0.021739  \n",
       "35  0.083333  \n",
       "36  0.166667  \n",
       "37  0.083333  \n",
       "38  0.125000  \n",
       "39  0.152174  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HH</th>\n",
       "      <td>0.504529</td>\n",
       "      <td>0.532457</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.443841</td>\n",
       "      <td>0.089852</td>\n",
       "      <td>0.037138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.504982</td>\n",
       "      <td>0.539402</td>\n",
       "      <td>0.019504</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KT</th>\n",
       "      <td>0.431159</td>\n",
       "      <td>0.376189</td>\n",
       "      <td>0.401268</td>\n",
       "      <td>0.434824</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.089674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LG</th>\n",
       "      <td>0.500453</td>\n",
       "      <td>0.489523</td>\n",
       "      <td>0.430254</td>\n",
       "      <td>0.522192</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>0.074728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LT</th>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.482492</td>\n",
       "      <td>0.493659</td>\n",
       "      <td>0.435771</td>\n",
       "      <td>0.161231</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>0.511775</td>\n",
       "      <td>0.556893</td>\n",
       "      <td>0.505435</td>\n",
       "      <td>0.494565</td>\n",
       "      <td>0.051286</td>\n",
       "      <td>0.053442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OB</th>\n",
       "      <td>0.631793</td>\n",
       "      <td>0.594275</td>\n",
       "      <td>0.674366</td>\n",
       "      <td>0.580616</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.131793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.515187</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.144313</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SS</th>\n",
       "      <td>0.457428</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.443388</td>\n",
       "      <td>0.450593</td>\n",
       "      <td>0.054178</td>\n",
       "      <td>0.053442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WO</th>\n",
       "      <td>0.482790</td>\n",
       "      <td>0.587607</td>\n",
       "      <td>0.589221</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.105755</td>\n",
       "      <td>0.121377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_PCT_1  shift_PCT_2       rms    rms0.5\n",
       "T_ID                                                                  \n",
       "HH    0.504529  0.532457     0.458333     0.443841  0.089852  0.037138\n",
       "HT    0.500000  0.493976     0.504982     0.539402  0.019504  0.020833\n",
       "KT    0.431159  0.376189     0.401268     0.434824  0.084700  0.089674\n",
       "LG    0.500453  0.489523     0.430254     0.522192  0.044770  0.074728\n",
       "LT    0.510417  0.482492     0.493659     0.435771  0.161231  0.156250\n",
       "NC    0.511775  0.556893     0.505435     0.494565  0.051286  0.053442\n",
       "OB    0.631793  0.594275     0.674366     0.580616  0.042592  0.131793\n",
       "SK    0.479167  0.515187     0.510417     0.562500  0.144313  0.083333\n",
       "SS    0.457428  0.458000     0.443388     0.450593  0.054178  0.053442\n",
       "WO    0.482790  0.587607     0.589221     0.593750  0.105755  0.121377"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"T_ID\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.562782</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>-0.062782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.475488</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>-0.024512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.443642</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.056358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.476182</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.065484</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.023818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.623317</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.123317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.494210</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.465275</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.118058</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.034725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>-0.065169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558253</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.551221</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.134554</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.051221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.552929</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>-0.052929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.481668</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.018332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.504773</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503625</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.502904</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.044571</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.443746</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.181254</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.056254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.423002</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.006335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SK</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.691095</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.316095</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.191095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.332091</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>-0.167909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304465</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.195535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.410340</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>-0.089660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.457859</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.083807</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WO</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.559112</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.184112</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.059112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.567982</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.220156</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.067982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.539791</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-0.039791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.683545</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.016878</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.149788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485762</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.479612</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.187055</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.020388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.489648</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.177019</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.474946</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.266612</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>-0.025054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SS</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456052</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.457208</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>-0.042792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.458477</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.063262</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.041523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SS</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.460264</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.043597</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.039736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.098462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.593481</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.073185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OB</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.596071</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.028929</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.096071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OB</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.589086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.063088</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>-0.089086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID         y    y_pred  shift_PCT_1  shift_PCT_2       rms    rms0.5  \\\n",
       "0    LG  0.608696  0.562782     0.583333     0.458333  0.045914  0.108696   \n",
       "1    LG  0.434783  0.475488     0.304348     0.652174  0.040705  0.065217   \n",
       "2    LG  0.416667  0.443642     0.291667     0.478261  0.026975  0.083333   \n",
       "3    LG  0.541667  0.476182     0.541667     0.500000  0.065484  0.041667   \n",
       "4    HH  0.500000  0.547024     0.500000     0.608696  0.047024  0.000000   \n",
       "5    HH  0.434783  0.623317     0.541667     0.333333  0.188535  0.065217   \n",
       "6    HH  0.500000  0.494210     0.416667     0.583333  0.005790  0.000000   \n",
       "7    HH  0.583333  0.465275     0.375000     0.250000  0.118058  0.083333   \n",
       "8    NC  0.565217  0.565169     0.500000     0.541667  0.000049  0.065217   \n",
       "9    NC  0.500000  0.558253     0.458333     0.541667  0.058253  0.000000   \n",
       "10   NC  0.416667  0.551221     0.521739     0.416667  0.134554  0.083333   \n",
       "11   NC  0.565217  0.552929     0.541667     0.478261  0.012288  0.065217   \n",
       "12   HT  0.458333  0.481668     0.500000     0.583333  0.023334  0.041667   \n",
       "13   HT  0.500000  0.485837     0.500000     0.782609  0.014163  0.000000   \n",
       "14   HT  0.541667  0.504773     0.541667     0.375000  0.036893  0.041667   \n",
       "15   HT  0.500000  0.503625     0.478261     0.416667  0.003625  0.000000   \n",
       "16   SK  0.458333  0.502904     0.458333     0.458333  0.044571  0.041667   \n",
       "17   SK  0.625000  0.443746     0.458333     0.416667  0.181254  0.125000   \n",
       "18   SK  0.458333  0.423002     0.500000     0.666667  0.035332  0.041667   \n",
       "19   SK  0.375000  0.691095     0.625000     0.708333  0.316095  0.125000   \n",
       "20   KT  0.291667  0.332091     0.333333     0.375000  0.040424  0.208333   \n",
       "21   KT  0.500000  0.304465     0.333333     0.166667  0.195535  0.000000   \n",
       "22   KT  0.391304  0.410340     0.416667     0.545455  0.019036  0.108696   \n",
       "23   KT  0.541667  0.457859     0.521739     0.652174  0.083807  0.041667   \n",
       "24   WO  0.375000  0.559112     0.625000     0.666667  0.184112  0.125000   \n",
       "25   WO  0.347826  0.567982     0.500000     0.541667  0.220156  0.152174   \n",
       "26   WO  0.541667  0.539791     0.666667     0.458333  0.001876  0.041667   \n",
       "27   WO  0.666667  0.683545     0.565217     0.708333  0.016878  0.166667   \n",
       "28   LT  0.500000  0.485762     0.375000     0.500000  0.014238  0.000000   \n",
       "29   LT  0.666667  0.479612     0.750000     0.590909  0.187055  0.166667   \n",
       "30   LT  0.666667  0.489648     0.458333     0.347826  0.177019  0.166667   \n",
       "31   LT  0.208333  0.474946     0.391304     0.304348  0.266612  0.291667   \n",
       "32   SS  0.500000  0.456052     0.500000     0.434783  0.043948  0.000000   \n",
       "33   SS  0.391304  0.457208     0.333333     0.454545  0.065904  0.108696   \n",
       "34   SS  0.521739  0.458477     0.565217     0.478261  0.063262  0.021739   \n",
       "35   SS  0.416667  0.460264     0.375000     0.434783  0.043597  0.083333   \n",
       "36   OB  0.666667  0.598462     0.666667     0.458333  0.068205  0.166667   \n",
       "37   OB  0.583333  0.593481     0.739130     0.739130  0.010148  0.083333   \n",
       "38   OB  0.625000  0.596071     0.625000     0.625000  0.028929  0.125000   \n",
       "39   OB  0.652174  0.589086     0.666667     0.500000  0.063088  0.152174   \n",
       "\n",
       "        diff  \n",
       "0  -0.062782  \n",
       "1  -0.024512  \n",
       "2  -0.056358  \n",
       "3   0.023818  \n",
       "4   0.047024  \n",
       "5   0.123317  \n",
       "6   0.005790  \n",
       "7   0.034725  \n",
       "8  -0.065169  \n",
       "9   0.058253  \n",
       "10  0.051221  \n",
       "11 -0.052929  \n",
       "12 -0.018332  \n",
       "13  0.014163  \n",
       "14 -0.004773  \n",
       "15  0.003625  \n",
       "16  0.002904  \n",
       "17  0.056254  \n",
       "18 -0.006335  \n",
       "19  0.191095  \n",
       "20 -0.167909  \n",
       "21  0.195535  \n",
       "22 -0.089660  \n",
       "23  0.042141  \n",
       "24  0.059112  \n",
       "25  0.067982  \n",
       "26 -0.039791  \n",
       "27 -0.149788  \n",
       "28  0.014238  \n",
       "29  0.020388  \n",
       "30  0.010352  \n",
       "31 -0.025054  \n",
       "32  0.043948  \n",
       "33 -0.042792  \n",
       "34  0.041523  \n",
       "35 -0.039736  \n",
       "36 -0.098462  \n",
       "37 -0.073185  \n",
       "38 -0.096071  \n",
       "39 -0.089086  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df[\"diff\"] = test_pred_df[\"rms\"] - test_pred_df[\"rms0.5\"]\n",
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
