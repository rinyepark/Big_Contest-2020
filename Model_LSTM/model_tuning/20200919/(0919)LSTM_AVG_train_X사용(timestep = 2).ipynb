{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data: augment_24group_1620.csv필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_lstm_train_X = pd.read_csv(\"AVG_lstm_final_train_X_hit.csv\")\n",
    "PCT_lstm_train_y = pd.read_csv(\"AVG_lstm_final_train_y_hit.csv\")\n",
    "\n",
    "PCT_lstm_test_X = pd.read_csv(\"AVG_lstm_final_test_X_hit.csv\")\n",
    "PCT_lstm_test_y = pd.read_csv(\"AVG_lstm_final_test_y_hit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = list(PCT_lstm_train_X.T_ID.unique())\n",
    "year = list(PCT_lstm_train_y.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) input shape로 변경 (row, timestep=2, feature)\n",
    "\n",
    "ex) \n",
    "timestep = 2\n",
    "\n",
    "* X_train_v 구성예시: [[1 ~ 24경기 데이터, 25 ~ 48경기 데이터], [49 ~ 72경기 데이터, 73 ~ 96경기 데이터] ]  \n",
    "X_train_v.shape >> (2,2*x)             # x: 각 24group에 대한 변수 개수\n",
    "* y_train_v 구성예시: 97 ~ 120 경기 승률\n",
    "\n",
    "=> reshape\n",
    "\n",
    "* X_train_v.shape >> (2,2,x)  # row, timestep, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성(LSTM)\n",
    "- optimizer: RMSprop -> lr(learning rate) 조절\n",
    "- LSTM: 모델이 계속 동일한 결과값이 나올 때, input 뉴런 개수를 늘려야 한다는 글을 읽고 계속 input 노드 개수를 바꿔주면서 모델 생성중\n",
    "- loss: MSE\n",
    "\n",
    "- early_stop: patience를 크게하면 과적합 되는 경우가 있어서 최대한 작게 설정해둠\n",
    "- batch_size: 모델이 계속 동일한 결과값이 나올 때, 데이터가 적어 batch size를 줄여보라는 글을 읽고 1로 설정해둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 53ms/sample - loss: 0.1791 - mae: 0.2020\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.9032e-04 - mae: 0.0141\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.5283e-05 - mae: 0.0064\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.3945e-05 - mae: 0.0056\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.6304e-05 - mae: 0.0057\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.6785e-05 - mae: 0.0052\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.7995e-05 - mae: 0.0048\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.5216e-05 - mae: 0.0055\n",
      "Epoch 00008: early stopping\n",
      "2016HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 55ms/sample - loss: 0.2913 - mae: 0.2447\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.7573e-04 - mae: 0.0220\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.5375e-04 - mae: 0.0132\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.4106e-04 - mae: 0.0120\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9365e-04 - mae: 0.0110\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.5406e-04 - mae: 0.0104\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0647e-04 - mae: 0.0084\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3476e-04 - mae: 0.0095\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.2111e-05 - mae: 0.0076\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.6087e-05 - mae: 0.0079\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.0373e-05 - mae: 0.0070\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.9431e-05 - mae: 0.0064\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.3685e-05 - mae: 0.0067\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.4736e-05 - mae: 0.0076\n",
      "Epoch 00014: early stopping\n",
      "2016NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 59ms/sample - loss: 0.2225 - mae: 0.2338\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.5262e-04 - mae: 0.0173\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.2222e-04 - mae: 0.0149\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.3964e-04 - mae: 0.0128\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2996e-04 - mae: 0.0127\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.6956e-04 - mae: 0.0106\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4451e-04 - mae: 0.0093\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1814e-04 - mae: 0.0085\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4227e-04 - mae: 0.0096\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1285e-04 - mae: 0.0085\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3551e-04 - mae: 0.0090\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.7342e-04 - mae: 0.0106\n",
      "Epoch 00012: early stopping\n",
      "2016HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 34ms/sample - loss: 0.1825 - mae: 0.1890\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.4662e-04 - mae: 0.0129\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2800e-04 - mae: 0.0092\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1148e-04 - mae: 0.0081\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2995e-04 - mae: 0.0089\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4162e-04 - mae: 0.0094\n",
      "Epoch 00006: early stopping\n",
      "2016SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 34ms/sample - loss: 0.2200 - mae: 0.2271\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.9697e-04 - mae: 0.0151\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4851e-04 - mae: 0.0103\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9009e-04 - mae: 0.0114\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.6870e-04 - mae: 0.0102\n",
      "Epoch 00005: early stopping\n",
      "2016KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 42ms/sample - loss: 0.2540 - mae: 0.2105\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.0422e-04 - mae: 0.0121\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.6429e-04 - mae: 0.0108\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.5640e-04 - mae: 0.0104\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.4836e-04 - mae: 0.0107\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.3914e-04 - mae: 0.0104\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.6440e-04 - mae: 0.010 - 0s 4ms/sample - loss: 1.7932e-04 - mae: 0.0106\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.6130e-04 - mae: 0.0106\n",
      "Epoch 00008: early stopping\n",
      "2016WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 41ms/sample - loss: 0.2700 - mae: 0.2413\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.8549e-04 - mae: 0.0107\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.2725e-05 - mae: 0.0075\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.8099e-05 - mae: 0.0065\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.1882e-05 - mae: 0.0074\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0031e-04 - mae: 0.0084\n",
      "Epoch 00006: early stopping\n",
      "2016LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 50ms/sample - loss: 0.2417 - mae: 0.2009\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.7239e-04 - mae: 0.0213\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.7539e-04 - mae: 0.0215\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.3196e-04 - mae: 0.0204\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.1363e-04 - mae: 0.0203\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.8178e-04 - mae: 0.0189\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.4171e-04 - mae: 0.0178\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.1635e-04 - mae: 0.0197\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.9205e-04 - mae: 0.0160\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.4302e-04 - mae: 0.0170\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.4890e-04 - mae: 0.0164\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.2369e-04 - mae: 0.0153\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.1269e-04 - mae: 0.0139\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.5384e-04 - mae: 0.0129\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.2134e-04 - mae: 0.0145\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2684e-04 - mae: 0.0126\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1094e-04 - mae: 0.0123\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.3949e-04 - mae: 0.0119\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.5104e-04 - mae: 0.0102\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1934e-04 - mae: 0.0092\n",
      "Epoch 21/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.7045e-05 - mae: 0.0080\n",
      "Epoch 22/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4683e-04 - mae: 0.0094\n",
      "Epoch 23/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3427e-04 - mae: 0.0093\n",
      "Epoch 00023: early stopping\n",
      "2016SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 42ms/sample - loss: 0.2047 - mae: 0.2207\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.9272e-04 - mae: 0.0224\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.6647e-04 - mae: 0.0216\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.8025e-04 - mae: 0.0210\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.3888e-04 - mae: 0.0208\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 4.5694e-04 - mae: 0.0184\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 4.7252e-04 - mae: 0.0167\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.8420e-04 - mae: 0.0181\n",
      "Epoch 00008: early stopping\n",
      "2016OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 63ms/sample - loss: 0.2625 - mae: 0.2239\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.8812e-05 - mae: 0.0075\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.9842e-05 - mae: 0.0052\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.1826e-05 - mae: 0.0060\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.6622e-05 - mae: 0.0048\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.6448e-05 - mae: 0.0046\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.9592e-05 - mae: 0.0043\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.5046e-05 - mae: 0.0048\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.9133e-05 - mae: 0.0051\n",
      "Epoch 00009: early stopping\n",
      "2017LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 39ms/sample - loss: 0.1805 - mae: 0.1854\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 2.2619e-04 - mae: 0.0123\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.6899e-04 - mae: 0.0104\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.6603e-04 - mae: 0.0099\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.2449e-04 - mae: 0.0087\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1670e-04 - mae: 0.0083\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.4355e-05 - mae: 0.0070\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.5595e-05 - mae: 0.0079\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.4860e-05 - mae: 0.0076\n",
      "Epoch 00009: early stopping\n",
      "2017HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.1740 - mae: 0.1941\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.0134e-04 - mae: 0.0122\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0585e-04 - mae: 0.0085\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0538e-04 - mae: 0.0086\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1045e-04 - mae: 0.0089\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.9186e-05 - mae: 0.0079\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.9024e-05 - mae: 0.0071\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.8119e-05 - mae: 0.0075\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.3877e-05 - mae: 0.0069\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.4111e-05 - mae: 0.0070\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.7396e-05 - mae: 0.0073\n",
      "Epoch 00011: early stopping\n",
      "2017NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 53ms/sample - loss: 0.1599 - mae: 0.1964\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.9384e-04 - mae: 0.0219\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.9793e-04 - mae: 0.0147\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.7213e-04 - mae: 0.0130\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1816e-04 - mae: 0.0126\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.4031e-04 - mae: 0.009 - 0s 3ms/sample - loss: 1.4311e-04 - mae: 0.0102\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2239e-04 - mae: 0.0093\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0271e-04 - mae: 0.0084\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.8236e-05 - mae: 0.0072\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.0194e-04 - mae: 0.0083\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 7.9021e-05 - mae: 0.0074\n",
      "Epoch 00011: early stopping\n",
      "2017HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 46ms/sample - loss: 0.1671 - mae: 0.1938\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.3739e-04 - mae: 0.0238\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.1209e-04 - mae: 0.0199\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.6902e-04 - mae: 0.0167\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.9719e-04 - mae: 0.0138\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.6160e-04 - mae: 0.0162\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1693e-04 - mae: 0.0128\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4150e-04 - mae: 0.0096\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2350e-04 - mae: 0.0088\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.5272e-04 - mae: 0.0102\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3446e-04 - mae: 0.0095\n",
      "Epoch 00011: early stopping\n",
      "2017SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.2357 - mae: 0.2223\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.3517e-04 - mae: 0.0157\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9653e-04 - mae: 0.0118\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.8893e-04 - mae: 0.0111\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.6186e-04 - mae: 0.0108\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.4652e-04 - mae: 0.0102\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.5339e-04 - mae: 0.0103\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.3503e-04 - mae: 0.0100\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.2951e-04 - mae: 0.0099\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.3186e-04 - mae: 0.0090\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.4672e-04 - mae: 0.0097\n",
      "Epoch 00011: early stopping\n",
      "2017KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.0955 - mae: 0.1637\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.7144e-04 - mae: 0.0262\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.7641e-04 - mae: 0.0165\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1044e-04 - mae: 0.0122\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1875e-04 - mae: 0.0087\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4978e-04 - mae: 0.0101\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3376e-04 - mae: 0.0093\n",
      "Epoch 00007: early stopping\n",
      "2017WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 44ms/sample - loss: 0.2000 - mae: 0.2086\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.1652e-04 - mae: 0.0144\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1286e-04 - mae: 0.0126\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9623e-04 - mae: 0.0113\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2398e-04 - mae: 0.0123\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.1082e-04 - mae: 0.0141\n",
      "Epoch 00006: early stopping\n",
      "2017LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.2015 - mae: 0.2053\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.6198e-04 - mae: 0.0100\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1049e-04 - mae: 0.0084\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.7835e-05 - mae: 0.0066\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.6469e-05 - mae: 0.0063\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.3065e-05 - mae: 0.0078\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.8620e-05 - mae: 0.0061\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.1622e-05 - mae: 0.0058\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.6707e-05 - mae: 0.0055\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.3912e-05 - mae: 0.0060\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.5983e-05 - mae: 0.0056\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.7710e-05 - mae: 0.0053\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.1906e-05 - mae: 0.0063\n",
      "Epoch 00013: early stopping\n",
      "2017SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 68ms/sample - loss: 0.1701 - mae: 0.1740\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.4526e-04 - mae: 0.0093\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.6712e-05 - mae: 0.0076\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.4731e-05 - mae: 0.0074\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.2758e-05 - mae: 0.0069\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.7036e-05 - mae: 0.0073\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2682e-04 - mae: 0.0095\n",
      "Epoch 00007: early stopping\n",
      "2017OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 47ms/sample - loss: 0.2874 - mae: 0.2544\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.5422e-04 - mae: 0.0136\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2737e-04 - mae: 0.0098\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.2781e-05 - mae: 0.0082\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1336e-04 - mae: 0.0086\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.6197e-05 - mae: 0.0080\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0933e-04 - mae: 0.0084\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0531e-04 - mae: 0.0080\n",
      "Epoch 00008: early stopping\n",
      "2018LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 43ms/sample - loss: 0.1779 - mae: 0.2129\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9969e-04 - mae: 0.0114\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1633e-04 - mae: 0.0087\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.6975e-05 - mae: 0.0078\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1666e-04 - mae: 0.0088\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3070e-04 - mae: 0.0094\n",
      "Epoch 00006: early stopping\n",
      "2018HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 47ms/sample - loss: 0.1576 - mae: 0.2011\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 3.3598e-04 - mae: 0.0143\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2317e-04 - mae: 0.0095\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2729e-04 - mae: 0.0089\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.7111e-05 - mae: 0.0078\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.9658e-05 - mae: 0.0083\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.1333e-05 - mae: 0.0074\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.1390e-05 - mae: 0.0082\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 7.2618e-05 - mae: 0.0067\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.7684e-05 - mae: 0.0064\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 4.9835e-05 - mae: 0.0059\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.7317e-05 - mae: 0.0059\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.6295e-05 - mae: 0.0079\n",
      "Epoch 00013: early stopping\n",
      "2018NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 4s 78ms/sample - loss: 0.2139 - mae: 0.2025\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.0968e-04 - mae: 0.0119\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.5641e-05 - mae: 0.0075\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.8745e-05 - mae: 0.0076\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.8642e-05 - mae: 0.0064\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.8231e-05 - mae: 0.0069\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.0605e-04 - mae: 0.0080\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 7.5658e-05 - mae: 0.0071\n",
      "Epoch 00008: early stopping\n",
      "2018HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 52ms/sample - loss: 0.2754 - mae: 0.2721\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.3061e-04 - mae: 0.0227\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9728e-04 - mae: 0.0118\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9820e-04 - mae: 0.0115\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2758e-04 - mae: 0.0125\n",
      "Epoch 00005: early stopping\n",
      "2018SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 42ms/sample - loss: 0.2494 - mae: 0.2202\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.9682e-04 - mae: 0.0120\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0165e-04 - mae: 0.0083\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.0204e-04 - mae: 0.0085\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.9931e-05 - mae: 0.0070\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.5628e-05 - mae: 0.0082\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2515e-04 - mae: 0.0093\n",
      "Epoch 00007: early stopping\n",
      "2018KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 44ms/sample - loss: 0.2434 - mae: 0.2376\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.7830e-04 - mae: 0.0139\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.7551e-04 - mae: 0.0103\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4547e-04 - mae: 0.0095\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2156e-04 - mae: 0.0127\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1888e-04 - mae: 0.0083\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.8029e-04 - mae: 0.0106\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.5873e-04 - mae: 0.0134\n",
      "Epoch 00008: early stopping\n",
      "2018WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 50ms/sample - loss: 0.3231 - mae: 0.2655\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 8.2329e-04 - mae: 0.0226\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.1031e-04 - mae: 0.0181\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 4.3281e-04 - mae: 0.0164\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.1402e-04 - mae: 0.0175\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 5.0317e-04 - mae: 0.0175\n",
      "Epoch 00006: early stopping\n",
      "2018LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 43ms/sample - loss: 0.1878 - mae: 0.2137\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.0943e-04 - mae: 0.0116\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2262e-04 - mae: 0.0091\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1801e-04 - mae: 0.0089\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1410e-04 - mae: 0.0086\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3953e-04 - mae: 0.0096 0s - loss: 1.2583e-04 - mae: 0.009\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2710e-04 - mae: 0.0090\n",
      "Epoch 00007: early stopping\n",
      "2018SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 61ms/sample - loss: 0.2885 - mae: 0.2499\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1292e-04 - mae: 0.0117\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.3853e-04 - mae: 0.0096\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.9194e-05 - mae: 0.0078\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0838e-04 - mae: 0.0081\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.7793e-05 - mae: 0.0058\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.3068e-05 - mae: 0.0043\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.9175e-05 - mae: 0.0050\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.4505e-05 - mae: 0.0048\n",
      "Epoch 00009: early stopping\n",
      "2018OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.2018 - mae: 0.2124\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.6443e-04 - mae: 0.0129\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0208e-04 - mae: 0.0084\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.5942e-05 - mae: 0.0071\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.8617e-05 - mae: 0.0069\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.6702e-05 - mae: 0.0068\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.5959e-05 - mae: 0.0076\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 6.3585e-05 - mae: 0.0065\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.9764e-05 - mae: 0.0073\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.7901e-05 - mae: 0.0070\n",
      "Epoch 00010: early stopping\n",
      "2019LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 49ms/sample - loss: 0.1537 - mae: 0.1969\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.6721e-04 - mae: 0.0213\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.3016e-04 - mae: 0.0174\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.9748e-04 - mae: 0.0171\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.8256e-04 - mae: 0.0163\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.1684e-04 - mae: 0.0148\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.0674e-04 - mae: 0.0148\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.0315e-04 - mae: 0.0115\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4625e-04 - mae: 0.0101\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.3906e-04 - mae: 0.0097\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.2013e-04 - mae: 0.0086\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1739e-04 - mae: 0.0084\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.7556e-05 - mae: 0.0071\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.5647e-05 - mae: 0.0062\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.3700e-05 - mae: 0.0065\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.5996e-05 - mae: 0.0071\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.0296e-05 - mae: 0.0066\n",
      "Epoch 00017: early stopping\n",
      "2019HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.1593 - mae: 0.1946\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2871e-04 - mae: 0.0103\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.7780e-04 - mae: 0.0084\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.8456e-04 - mae: 0.0109\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.6943e-04 - mae: 0.0099\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.2132e-04 - mae: 0.0071\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.0850e-04 - mae: 0.0085\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.3976e-04 - mae: 0.0093\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.9166e-05 - mae: 0.0075\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.1673e-04 - mae: 0.0083\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1210e-04 - mae: 0.0081\n",
      "Epoch 00011: early stopping\n",
      "2019NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.2414 - mae: 0.2189\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.6280e-04 - mae: 0.0189\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.2898e-04 - mae: 0.0186\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.5242e-04 - mae: 0.0176\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.8546e-04 - mae: 0.0166\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.6184e-04 - mae: 0.0143\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.2293e-04 - mae: 0.0141\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.8304e-04 - mae: 0.0131\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.9509e-04 - mae: 0.0139\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 1.7544e-04 - mae: 0.0112\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 2.1775e-04 - mae: 0.0120\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.8211e-04 - mae: 0.0100\n",
      "Epoch 00012: early stopping\n",
      "2019HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 43ms/sample - loss: 0.1682 - mae: 0.1918\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.3921e-04 - mae: 0.0124\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.7089e-05 - mae: 0.0051\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.1996e-05 - mae: 0.0053\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.6377e-05 - mae: 0.0050\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.4407e-05 - mae: 0.0049\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 3.0695e-05 - mae: 0.0043\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 4.7128e-05 - mae: 0.0055\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.4190e-05 - mae: 0.0061\n",
      "Epoch 00009: early stopping\n",
      "2019SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 4s 72ms/sample - loss: 0.2302 - mae: 0.2224\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.3163e-04 - mae: 0.0122\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.1086e-04 - mae: 0.0090\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.8959e-05 - mae: 0.0084\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.7656e-05 - mae: 0.0082\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.1009e-04 - mae: 0.0087\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.2516e-04 - mae: 0.0092\n",
      "Epoch 00007: early stopping\n",
      "2019KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 31ms/sample - loss: 0.1918 - mae: 0.2053\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.6283e-04 - mae: 0.0185\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.3640e-04 - mae: 0.0155\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.0828e-04 - mae: 0.0151\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.9356e-04 - mae: 0.0119\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.8612e-04 - mae: 0.0111\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.8736e-04 - mae: 0.0109\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 8.9145e-05 - mae: 0.0075\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.4391e-05 - mae: 0.0085\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.2100e-04 - mae: 0.0095\n",
      "Epoch 00010: early stopping\n",
      "2019WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 36ms/sample - loss: 0.2359 - mae: 0.2306\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 7.8723e-04 - mae: 0.0238\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 4.3359e-04 - mae: 0.0168\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 2.3139e-04 - mae: 0.0128\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.4399e-04 - mae: 0.0099\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.2364e-04 - mae: 0.0124\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.0114e-04 - mae: 0.0082\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - ETA: 0s - loss: 1.0508e-04 - mae: 0.008 - 0s 2ms/sample - loss: 1.0496e-04 - mae: 0.0080\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 9.3621e-05 - mae: 0.0076\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.4612e-05 - mae: 0.0066\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.3010e-05 - mae: 0.0056\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 6.5272e-05 - mae: 0.0068\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 9.5358e-05 - mae: 0.0080\n",
      "Epoch 00013: early stopping\n",
      "2019LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 34ms/sample - loss: 0.1649 - mae: 0.1945\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 5.9223e-04 - mae: 0.0194 0s - loss: 6.5659e-04 - mae: 0.020\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.4277e-04 - mae: 0.0151\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.2308e-04 - mae: 0.0138\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.0956e-04 - mae: 0.0137\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.7263e-04 - mae: 0.0138\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.1013e-04 - mae: 0.0113\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 2.5085e-04 - mae: 0.0122\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.6001e-04 - mae: 0.0147\n",
      "Epoch 00009: early stopping\n",
      "2019SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 33ms/sample - loss: 0.1791 - mae: 0.2107\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 2.6686e-04 - mae: 0.0133\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1148e-04 - mae: 0.0079\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0351e-04 - mae: 0.0076\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.0563e-04 - mae: 0.0081\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.1247e-04 - mae: 0.0086\n",
      "Epoch 00006: early stopping\n",
      "2019OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               58800     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,901\n",
      "Trainable params: 58,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 33ms/sample - loss: 0.1803 - mae: 0.1951\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 3.3298e-04 - mae: 0.0158\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 2.2302e-04 - mae: 0.0126\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 2.1647e-04 - mae: 0.0119\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 2.5770e-04 - mae: 0.0134\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.1958e-04 - mae: 0.0086\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 1.0451e-04 - mae: 0.0081\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.3217e-04 - mae: 0.0093\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 8.4555e-05 - mae: 0.0075\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 1.0369e-04 - mae: 0.0083\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 9.7204e-05 - mae: 0.0079\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred',\"shift_AVG_1\",\"shift_AVG_2\",'MSE','MSE_avg'])\n",
    "\n",
    "idx = 0\n",
    "for y in year:\n",
    "    tmp1 = PCT_lstm_train_X[PCT_lstm_train_X[\"YEAR\"] == y]\n",
    "    tmp2 = PCT_lstm_train_y[PCT_lstm_train_y[\"YEAR\"] == y]\n",
    "    tmp3 = PCT_lstm_test_X[PCT_lstm_test_X[\"YEAR\"] == y]\n",
    "    tmp4 = PCT_lstm_test_y[PCT_lstm_test_y[\"YEAR\"] == y]\n",
    "    for t in team:\n",
    "        name = '{}{}'.format(y,t)\n",
    "        print(name,\"=======================================\")\n",
    "        \n",
    "        X_train = tmp1[tmp1[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "        y_train = tmp2[tmp2[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        X_test = tmp3[tmp3[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        y_test = tmp4[tmp4[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        \n",
    "        X_train_v = X_train.values\n",
    "        y_train_v = y_train.values\n",
    "\n",
    "        X_test_v = X_test.values\n",
    "        y_test_v = y_test.values\n",
    "        \n",
    "        X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,X_train_v.shape[1]//2)\n",
    "        X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,X_test_v.shape[1]//2)\n",
    "        \n",
    "        ## model\n",
    "        K.clear_session() \n",
    "\n",
    "        model = Sequential()\n",
    "        optimizer = Adam(lr=0.01)\n",
    "#         optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "        model.add(LSTM(100,input_shape = (2,X_train_v.shape[1]//2))) # (timestep, feature)\n",
    "        model.add(Dense(1)) # output = 1\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "#         hist1 = model.fit(X_train_t, y_train_v, epochs=100, batch_size=1, verbose=1)\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "        hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "                  batch_size=1, verbose=1, callbacks=[early_stop])\n",
    "        ##\n",
    "        \n",
    "        model_dict[name] = model\n",
    "        hist_dict[name] = hist1\n",
    "        \n",
    "        y_pred = model.predict(X_test_t)\n",
    "        mse = mean_squared_error(y_test_v, y_pred)\n",
    "        mse_avg = mean_squared_error(y_test_v,[y_train.mean()[0]])\n",
    "        \n",
    "        \n",
    "        test_pred_df.loc[idx,:] = [y,t,y_test_v.reshape(-1)[0],y_pred.reshape(-1)[0],\n",
    "                                  X_test.loc[X_test.index[0],[\"shift_AVG_1\"]][0],\n",
    "                                  X_test.loc[X_test.index[0],[\"shift_AVG_2\"]][0], mse,mse_avg]\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "test_pred_df[['y','y_pred',\"shift_AVG_1\",\"shift_AVG_2\",'MSE','MSE_avg']] = test_pred_df[['y','y_pred',\"shift_AVG_1\",\"shift_AVG_2\",'MSE','MSE_avg']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00038374803900388763"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred_df['y'],test_pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.sort_values(by=[\"YEAR\",\"T_ID\"]).to_csv(\"AVG_t2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래 데이터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCT_lstm_train_X = pd.read_csv(\"AVG_lstm_final_train_X_hit.csv\")\n",
    "# PCT_lstm_train_y = pd.read_csv(\"AVG_lstm_final_train_y_hit.csv\")\n",
    "\n",
    "# PCT_lstm_test_X = pd.read_csv(\"AVG_lstm_final_test_X_hit.csv\")\n",
    "# PCT_lstm_test_y = pd.read_csv(\"AVG_lstm_final_test_y_hit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_AVG_1</th>\n",
       "      <th>shift_AVG_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.291146</td>\n",
       "      <td>0.287639</td>\n",
       "      <td>0.292375</td>\n",
       "      <td>0.296354</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.015759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.283259</td>\n",
       "      <td>0.284698</td>\n",
       "      <td>0.293109</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.022077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.285146</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.293297</td>\n",
       "      <td>0.283993</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.012738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.275120</td>\n",
       "      <td>0.269043</td>\n",
       "      <td>0.272767</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.015692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_AVG_1  shift_AVG_2       rms   rms_avg\n",
       "YEAR                                                                  \n",
       "2016  0.291146  0.287639     0.292375     0.296354  0.021336  0.015759\n",
       "2017  0.291601  0.283259     0.284698     0.293109  0.021382  0.022077\n",
       "2018  0.285146  0.284798     0.293297     0.283993  0.015053  0.012738\n",
       "2019  0.257812  0.275120     0.269043     0.272767  0.019414  0.015692"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_AVG_1</th>\n",
       "      <th>shift_AVG_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>0.284477</td>\n",
       "      <td>0.294471</td>\n",
       "      <td>0.297110</td>\n",
       "      <td>0.011592</td>\n",
       "      <td>0.003896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.288575</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.314581</td>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.015654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.287440</td>\n",
       "      <td>0.270977</td>\n",
       "      <td>0.294611</td>\n",
       "      <td>0.286241</td>\n",
       "      <td>0.016463</td>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.315041</td>\n",
       "      <td>0.293286</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.058302</td>\n",
       "      <td>0.044809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.299972</td>\n",
       "      <td>0.286055</td>\n",
       "      <td>0.308046</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.003316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.268301</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.293155</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>0.326291</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.018902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.309893</td>\n",
       "      <td>0.265357</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.028417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.283863</td>\n",
       "      <td>0.276533</td>\n",
       "      <td>0.329186</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.006915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.298225</td>\n",
       "      <td>0.286373</td>\n",
       "      <td>0.297974</td>\n",
       "      <td>0.285885</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.006851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.274136</td>\n",
       "      <td>0.277432</td>\n",
       "      <td>0.251225</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.019175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.272944</td>\n",
       "      <td>0.290581</td>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>0.025468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.329682</td>\n",
       "      <td>0.268032</td>\n",
       "      <td>0.261671</td>\n",
       "      <td>0.302850</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.032941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>0.300874</td>\n",
       "      <td>0.292476</td>\n",
       "      <td>0.344456</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.029528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>0.264310</td>\n",
       "      <td>0.279268</td>\n",
       "      <td>0.275946</td>\n",
       "      <td>0.019850</td>\n",
       "      <td>0.018217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.263965</td>\n",
       "      <td>0.292121</td>\n",
       "      <td>0.261635</td>\n",
       "      <td>0.039627</td>\n",
       "      <td>0.028342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.297396</td>\n",
       "      <td>0.292108</td>\n",
       "      <td>0.283816</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.018768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.297794</td>\n",
       "      <td>0.272680</td>\n",
       "      <td>0.286738</td>\n",
       "      <td>0.277051</td>\n",
       "      <td>0.025114</td>\n",
       "      <td>0.021017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.291216</td>\n",
       "      <td>0.310658</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.007964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.288757</td>\n",
       "      <td>0.306109</td>\n",
       "      <td>0.289246</td>\n",
       "      <td>0.318025</td>\n",
       "      <td>0.017352</td>\n",
       "      <td>0.019347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.268675</td>\n",
       "      <td>0.313141</td>\n",
       "      <td>0.301038</td>\n",
       "      <td>0.289504</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0.026804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.268664</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.007269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.273120</td>\n",
       "      <td>0.276301</td>\n",
       "      <td>0.252888</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.277275</td>\n",
       "      <td>0.305065</td>\n",
       "      <td>0.286747</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.006432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.296218</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.285185</td>\n",
       "      <td>0.021129</td>\n",
       "      <td>0.008198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.256809</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.282660</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.011870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.266908</td>\n",
       "      <td>0.260595</td>\n",
       "      <td>0.334816</td>\n",
       "      <td>0.272093</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.023770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.285985</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.282735</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.009391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.295063</td>\n",
       "      <td>0.291615</td>\n",
       "      <td>0.291569</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.316629</td>\n",
       "      <td>0.324558</td>\n",
       "      <td>0.310142</td>\n",
       "      <td>0.327334</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.261041</td>\n",
       "      <td>0.254279</td>\n",
       "      <td>0.252207</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.265525</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.034012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.301850</td>\n",
       "      <td>0.275735</td>\n",
       "      <td>0.317497</td>\n",
       "      <td>0.046239</td>\n",
       "      <td>0.035406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.264524</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.265133</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.233207</td>\n",
       "      <td>0.275072</td>\n",
       "      <td>0.262893</td>\n",
       "      <td>0.275610</td>\n",
       "      <td>0.041866</td>\n",
       "      <td>0.027251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.265664</td>\n",
       "      <td>0.263461</td>\n",
       "      <td>0.268999</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.013485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.280680</td>\n",
       "      <td>0.292941</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.298266</td>\n",
       "      <td>0.287286</td>\n",
       "      <td>0.268949</td>\n",
       "      <td>0.029609</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.279376</td>\n",
       "      <td>0.271048</td>\n",
       "      <td>0.238825</td>\n",
       "      <td>0.279597</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.009428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.255786</td>\n",
       "      <td>0.258064</td>\n",
       "      <td>0.257822</td>\n",
       "      <td>0.271845</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.004266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred  shift_AVG_1  shift_AVG_2       rms  \\\n",
       "0   2016   LG  0.296069  0.284477     0.294471     0.297110  0.011592   \n",
       "1   2016   HH  0.288575  0.316201     0.293083     0.314581  0.027626   \n",
       "2   2016   NC  0.287440  0.270977     0.294611     0.286241  0.016463   \n",
       "3   2016   HT  0.256739  0.315041     0.293286     0.313860  0.058302   \n",
       "4   2016   SK  0.305263  0.299972     0.286055     0.308046  0.005292   \n",
       "5   2016   KT  0.295455  0.268301     0.281437     0.262626  0.027153   \n",
       "6   2016   WO  0.289941  0.293155     0.297398     0.326291  0.003215   \n",
       "7   2016   LT  0.309893  0.265357     0.256250     0.285211  0.044536   \n",
       "8   2016   SS  0.283863  0.276533     0.329186     0.283688  0.007330   \n",
       "9   2016   OB  0.298225  0.286373     0.297974     0.285885  0.011852   \n",
       "10  2017   LG  0.274136  0.277432     0.251225     0.300725  0.003296   \n",
       "11  2017   HH  0.272944  0.290581     0.291463     0.300000  0.017637   \n",
       "12  2017   NC  0.329682  0.268032     0.261671     0.302850  0.061650   \n",
       "13  2017   HT  0.294464  0.300874     0.292476     0.344456  0.006410   \n",
       "14  2017   SK  0.284160  0.264310     0.279268     0.275946  0.019850   \n",
       "15  2017   KT  0.303592  0.263965     0.292121     0.261635  0.039627   \n",
       "16  2017   WO  0.276888  0.297396     0.292108     0.283816  0.020508   \n",
       "17  2017   LT  0.297794  0.272680     0.286738     0.277051  0.025114   \n",
       "18  2017   SS  0.293588  0.291216     0.310658     0.266585  0.002373   \n",
       "19  2017   OB  0.288757  0.306109     0.289246     0.318025  0.017352   \n",
       "20  2018   LG  0.268675  0.313141     0.301038     0.289504  0.044466   \n",
       "21  2018   HH  0.270758  0.268664     0.286915     0.271186  0.002094   \n",
       "22  2018   NC  0.283636  0.273120     0.276301     0.252888  0.010516   \n",
       "23  2018   HT  0.293083  0.277275     0.305065     0.286747  0.015808   \n",
       "24  2018   SK  0.275089  0.296218     0.283333     0.285185  0.021129   \n",
       "25  2018   KT  0.280925  0.256809     0.262500     0.282660  0.024116   \n",
       "26  2018   WO  0.266908  0.260595     0.334816     0.272093  0.006314   \n",
       "27  2018   LT  0.300691  0.285985     0.281287     0.282735  0.014706   \n",
       "28  2018   SS  0.295063  0.291615     0.291569     0.289598  0.003449   \n",
       "29  2018   OB  0.316629  0.324558     0.310142     0.327334  0.007929   \n",
       "30  2019   LG  0.258809  0.261041     0.254279     0.252207  0.002232   \n",
       "31  2019   HH  0.236341  0.265525     0.286219     0.260763  0.029184   \n",
       "32  2019   NC  0.255611  0.301850     0.275735     0.317497  0.046239   \n",
       "33  2019   HT  0.264524  0.276189     0.265432     0.265133  0.011665   \n",
       "34  2019   SK  0.233207  0.275072     0.262893     0.275610  0.041866   \n",
       "35  2019   KT  0.265664  0.263461     0.268999     0.261538  0.002203   \n",
       "36  2019   WO  0.260143  0.280680     0.292941     0.274533  0.020537   \n",
       "37  2019   LT  0.268657  0.298266     0.287286     0.268949  0.029609   \n",
       "38  2019   SS  0.279376  0.271048     0.238825     0.279597  0.008329   \n",
       "39  2019   OB  0.255786  0.258064     0.257822     0.271845  0.002279   \n",
       "\n",
       "     rms_avg  \n",
       "0   0.003896  \n",
       "1   0.015654  \n",
       "2   0.000565  \n",
       "3   0.044809  \n",
       "4   0.003316  \n",
       "5   0.028266  \n",
       "6   0.018902  \n",
       "7   0.028417  \n",
       "8   0.006915  \n",
       "9   0.006851  \n",
       "10  0.019175  \n",
       "11  0.025468  \n",
       "12  0.032941  \n",
       "13  0.029528  \n",
       "14  0.018217  \n",
       "15  0.028342  \n",
       "16  0.018768  \n",
       "17  0.021017  \n",
       "18  0.007964  \n",
       "19  0.019347  \n",
       "20  0.026804  \n",
       "21  0.007269  \n",
       "22  0.021118  \n",
       "23  0.006432  \n",
       "24  0.008198  \n",
       "25  0.011870  \n",
       "26  0.023770  \n",
       "27  0.009391  \n",
       "28  0.003287  \n",
       "29  0.009247  \n",
       "30  0.000801  \n",
       "31  0.034012  \n",
       "32  0.035406  \n",
       "33  0.007147  \n",
       "34  0.027251  \n",
       "35  0.013485  \n",
       "36  0.017787  \n",
       "37  0.007334  \n",
       "38  0.009428  \n",
       "39  0.004266  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3438337229787254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "tmp = test_pred_df.copy()\n",
    "# tmp['half']= 0.5\n",
    "r2_y_predict = r2_score(tmp['y'], tmp['y_pred'])\n",
    "r2_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 파일 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCT_lstm_train_X = pd.read_csv(\"AVG_lstm_final_train_X.csv\")\n",
    "# PCT_lstm_train_y = pd.read_csv(\"AVG_lstm_final_train_y.csv\")\n",
    "\n",
    "# PCT_lstm_test_X = pd.read_csv(\"AVG_lstm_final_test_X.csv\")\n",
    "# PCT_lstm_test_y = pd.read_csv(\"AVG_lstm_final_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_AVG_1</th>\n",
       "      <th>shift_AVG_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.291146</td>\n",
       "      <td>0.292641</td>\n",
       "      <td>0.292375</td>\n",
       "      <td>0.296354</td>\n",
       "      <td>0.018380</td>\n",
       "      <td>0.015759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.290575</td>\n",
       "      <td>0.284698</td>\n",
       "      <td>0.293109</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>0.022077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.285146</td>\n",
       "      <td>0.285081</td>\n",
       "      <td>0.293297</td>\n",
       "      <td>0.283993</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>0.012738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.257812</td>\n",
       "      <td>0.261197</td>\n",
       "      <td>0.269043</td>\n",
       "      <td>0.272767</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.015692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_AVG_1  shift_AVG_2       rms   rms_avg\n",
       "YEAR                                                                  \n",
       "2016  0.291146  0.292641     0.292375     0.296354  0.018380  0.015759\n",
       "2017  0.291601  0.290575     0.284698     0.293109  0.020686  0.022077\n",
       "2018  0.285146  0.285081     0.293297     0.283993  0.012775  0.012738\n",
       "2019  0.257812  0.261197     0.269043     0.272767  0.016623  0.015692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_AVG_1</th>\n",
       "      <th>shift_AVG_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>0.293986</td>\n",
       "      <td>0.294471</td>\n",
       "      <td>0.297110</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.003896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.288575</td>\n",
       "      <td>0.310350</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.314581</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>0.015654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.287440</td>\n",
       "      <td>0.311469</td>\n",
       "      <td>0.294611</td>\n",
       "      <td>0.286241</td>\n",
       "      <td>0.024029</td>\n",
       "      <td>0.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.299722</td>\n",
       "      <td>0.293286</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.042983</td>\n",
       "      <td>0.044809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.296655</td>\n",
       "      <td>0.286055</td>\n",
       "      <td>0.308046</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>0.003316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.266835</td>\n",
       "      <td>0.281437</td>\n",
       "      <td>0.262626</td>\n",
       "      <td>0.028620</td>\n",
       "      <td>0.028266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.293779</td>\n",
       "      <td>0.297398</td>\n",
       "      <td>0.326291</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.018902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.309893</td>\n",
       "      <td>0.273169</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>0.285211</td>\n",
       "      <td>0.036723</td>\n",
       "      <td>0.028417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.283863</td>\n",
       "      <td>0.290610</td>\n",
       "      <td>0.329186</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>0.006915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.298225</td>\n",
       "      <td>0.289828</td>\n",
       "      <td>0.297974</td>\n",
       "      <td>0.285885</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.006851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.274136</td>\n",
       "      <td>0.310476</td>\n",
       "      <td>0.251225</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>0.036340</td>\n",
       "      <td>0.019175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.272944</td>\n",
       "      <td>0.309531</td>\n",
       "      <td>0.291463</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.025468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.329682</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>0.261671</td>\n",
       "      <td>0.302850</td>\n",
       "      <td>0.030999</td>\n",
       "      <td>0.032941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>0.275053</td>\n",
       "      <td>0.292476</td>\n",
       "      <td>0.344456</td>\n",
       "      <td>0.019411</td>\n",
       "      <td>0.029528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>0.260247</td>\n",
       "      <td>0.279268</td>\n",
       "      <td>0.275946</td>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.018217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.291121</td>\n",
       "      <td>0.292121</td>\n",
       "      <td>0.261635</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.028342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.283369</td>\n",
       "      <td>0.292108</td>\n",
       "      <td>0.283816</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.018768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.297794</td>\n",
       "      <td>0.281346</td>\n",
       "      <td>0.286738</td>\n",
       "      <td>0.277051</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.021017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>0.310658</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.007964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.288757</td>\n",
       "      <td>0.307652</td>\n",
       "      <td>0.289246</td>\n",
       "      <td>0.318025</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>0.019347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.268675</td>\n",
       "      <td>0.313541</td>\n",
       "      <td>0.301038</td>\n",
       "      <td>0.289504</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>0.026804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.280807</td>\n",
       "      <td>0.286915</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>0.007269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.264281</td>\n",
       "      <td>0.276301</td>\n",
       "      <td>0.252888</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.021118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.294615</td>\n",
       "      <td>0.305065</td>\n",
       "      <td>0.286747</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.006432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.270654</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.285185</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>0.008198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.258651</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.282660</td>\n",
       "      <td>0.022274</td>\n",
       "      <td>0.011870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.266908</td>\n",
       "      <td>0.269440</td>\n",
       "      <td>0.334816</td>\n",
       "      <td>0.272093</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.023770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.286443</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.282735</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.009391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.295063</td>\n",
       "      <td>0.291178</td>\n",
       "      <td>0.291569</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.316629</td>\n",
       "      <td>0.321205</td>\n",
       "      <td>0.310142</td>\n",
       "      <td>0.327334</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.236035</td>\n",
       "      <td>0.254279</td>\n",
       "      <td>0.252207</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.257743</td>\n",
       "      <td>0.286219</td>\n",
       "      <td>0.260763</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>0.034012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.283232</td>\n",
       "      <td>0.275735</td>\n",
       "      <td>0.317497</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>0.035406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.264524</td>\n",
       "      <td>0.271931</td>\n",
       "      <td>0.265432</td>\n",
       "      <td>0.265133</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.233207</td>\n",
       "      <td>0.251132</td>\n",
       "      <td>0.262893</td>\n",
       "      <td>0.275610</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.027251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.265664</td>\n",
       "      <td>0.237244</td>\n",
       "      <td>0.268999</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.028420</td>\n",
       "      <td>0.013485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.279308</td>\n",
       "      <td>0.292941</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.017787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.271239</td>\n",
       "      <td>0.287286</td>\n",
       "      <td>0.268949</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.279376</td>\n",
       "      <td>0.264379</td>\n",
       "      <td>0.238825</td>\n",
       "      <td>0.279597</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.009428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.255786</td>\n",
       "      <td>0.259721</td>\n",
       "      <td>0.257822</td>\n",
       "      <td>0.271845</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.004266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred  shift_AVG_1  shift_AVG_2       rms  \\\n",
       "0   2016   LG  0.296069  0.293986     0.294471     0.297110  0.002082   \n",
       "1   2016   HH  0.288575  0.310350     0.293083     0.314581  0.021776   \n",
       "2   2016   NC  0.287440  0.311469     0.294611     0.286241  0.024029   \n",
       "3   2016   HT  0.256739  0.299722     0.293286     0.313860  0.042983   \n",
       "4   2016   SK  0.305263  0.296655     0.286055     0.308046  0.008608   \n",
       "5   2016   KT  0.295455  0.266835     0.281437     0.262626  0.028620   \n",
       "6   2016   WO  0.289941  0.293779     0.297398     0.326291  0.003839   \n",
       "7   2016   LT  0.309893  0.273169     0.256250     0.285211  0.036723   \n",
       "8   2016   SS  0.283863  0.290610     0.329186     0.283688  0.006747   \n",
       "9   2016   OB  0.298225  0.289828     0.297974     0.285885  0.008397   \n",
       "10  2017   LG  0.274136  0.310476     0.251225     0.300725  0.036340   \n",
       "11  2017   HH  0.272944  0.309531     0.291463     0.300000  0.036587   \n",
       "12  2017   NC  0.329682  0.298683     0.261671     0.302850  0.030999   \n",
       "13  2017   HT  0.294464  0.275053     0.292476     0.344456  0.019411   \n",
       "14  2017   SK  0.284160  0.260247     0.279268     0.275946  0.023913   \n",
       "15  2017   KT  0.303592  0.291121     0.292121     0.261635  0.012471   \n",
       "16  2017   WO  0.276888  0.283369     0.292108     0.283816  0.006481   \n",
       "17  2017   LT  0.297794  0.281346     0.286738     0.277051  0.016448   \n",
       "18  2017   SS  0.293588  0.288273     0.310658     0.266585  0.005315   \n",
       "19  2017   OB  0.288757  0.307652     0.289246     0.318025  0.018894   \n",
       "20  2018   LG  0.268675  0.313541     0.301038     0.289504  0.044866   \n",
       "21  2018   HH  0.270758  0.280807     0.286915     0.271186  0.010049   \n",
       "22  2018   NC  0.283636  0.264281     0.276301     0.252888  0.019355   \n",
       "23  2018   HT  0.293083  0.294615     0.305065     0.286747  0.001532   \n",
       "24  2018   SK  0.275089  0.270654     0.283333     0.285185  0.004434   \n",
       "25  2018   KT  0.280925  0.258651     0.262500     0.282660  0.022274   \n",
       "26  2018   WO  0.266908  0.269440     0.334816     0.272093  0.002532   \n",
       "27  2018   LT  0.300691  0.286443     0.281287     0.282735  0.014248   \n",
       "28  2018   SS  0.295063  0.291178     0.291569     0.289598  0.003886   \n",
       "29  2018   OB  0.316629  0.321205     0.310142     0.327334  0.004577   \n",
       "30  2019   LG  0.258809  0.236035     0.254279     0.252207  0.022774   \n",
       "31  2019   HH  0.236341  0.257743     0.286219     0.260763  0.021403   \n",
       "32  2019   NC  0.255611  0.283232     0.275735     0.317497  0.027621   \n",
       "33  2019   HT  0.264524  0.271931     0.265432     0.265133  0.007407   \n",
       "34  2019   SK  0.233207  0.251132     0.262893     0.275610  0.017926   \n",
       "35  2019   KT  0.265664  0.237244     0.268999     0.261538  0.028420   \n",
       "36  2019   WO  0.260143  0.279308     0.292941     0.274533  0.019164   \n",
       "37  2019   LT  0.268657  0.271239     0.287286     0.268949  0.002582   \n",
       "38  2019   SS  0.279376  0.264379     0.238825     0.279597  0.014997   \n",
       "39  2019   OB  0.255786  0.259721     0.257822     0.271845  0.003935   \n",
       "\n",
       "     rms_avg  \n",
       "0   0.003896  \n",
       "1   0.015654  \n",
       "2   0.000565  \n",
       "3   0.044809  \n",
       "4   0.003316  \n",
       "5   0.028266  \n",
       "6   0.018902  \n",
       "7   0.028417  \n",
       "8   0.006915  \n",
       "9   0.006851  \n",
       "10  0.019175  \n",
       "11  0.025468  \n",
       "12  0.032941  \n",
       "13  0.029528  \n",
       "14  0.018217  \n",
       "15  0.028342  \n",
       "16  0.018768  \n",
       "17  0.021017  \n",
       "18  0.007964  \n",
       "19  0.019347  \n",
       "20  0.026804  \n",
       "21  0.007269  \n",
       "22  0.021118  \n",
       "23  0.006432  \n",
       "24  0.008198  \n",
       "25  0.011870  \n",
       "26  0.023770  \n",
       "27  0.009391  \n",
       "28  0.003287  \n",
       "29  0.009247  \n",
       "30  0.000801  \n",
       "31  0.034012  \n",
       "32  0.035406  \n",
       "33  0.007147  \n",
       "34  0.027251  \n",
       "35  0.013485  \n",
       "36  0.017787  \n",
       "37  0.007334  \n",
       "38  0.009428  \n",
       "39  0.004266  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
