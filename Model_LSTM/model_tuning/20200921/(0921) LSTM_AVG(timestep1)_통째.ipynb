{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data: augment_24group_1620.csv필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_X = pd.read_csv(\"AVG/new_AVG_train_X.csv\")\n",
    "lstm_train_y = pd.read_csv(\"AVG/AVG_train_y.csv\")\n",
    "\n",
    "lstm_test_X = pd.read_csv(\"AVG/new_AVG_test_X.csv\")\n",
    "lstm_test_y = pd.read_csv(\"AVG/AVG_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = list(lstm_train_X.T_ID.unique())\n",
    "year = list(lstm_train_y.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) input shape로 변경 (row, timestep=2, feature)\n",
    "\n",
    "ex) \n",
    "timestep = 2\n",
    "\n",
    "* X_train_v 구성예시: [[1 ~ 24경기 데이터, 25 ~ 48경기 데이터], [49 ~ 72경기 데이터, 73 ~ 96경기 데이터] ]  \n",
    "X_train_v.shape >> (2,2*x)             # x: 각 24group에 대한 변수 개수\n",
    "* y_train_v 구성예시: 97 ~ 120 경기 승률\n",
    "\n",
    "=> reshape\n",
    "\n",
    "* X_train_v.shape >> (2,2,x)  # row, timestep, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성(LSTM)\n",
    "- optimizer: RMSprop -> lr(learning rate) 조절\n",
    "- LSTM: 모델이 계속 동일한 결과값이 나올 때, input 뉴런 개수를 늘려야 한다는 글을 읽고 계속 input 노드 개수를 바꿔주면서 모델 생성중\n",
    "- loss: MSE\n",
    "\n",
    "- early_stop: patience를 크게하면 과적합 되는 경우가 있어서 최대한 작게 설정해둠\n",
    "- batch_size: 모델이 계속 동일한 결과값이 나올 때, 데이터가 적어 batch size를 줄여보라는 글을 읽고 1로 설정해둠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:red\"> MSE로 통일했습니다! </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200)               234400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 234,601\n",
      "Trainable params: 234,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2336 samples, validate on 584 samples\n",
      "Epoch 1/100\n",
      "2336/2336 [==============================] - 4s 2ms/sample - loss: 0.0362 - mae: 0.0418 - val_loss: 7.0564e-04 - val_mae: 0.0231\n",
      "Epoch 2/100\n",
      "2336/2336 [==============================] - 2s 1ms/sample - loss: 4.2548e-04 - mae: 0.0164 - val_loss: 6.3025e-04 - val_mae: 0.0214\n",
      "Epoch 3/100\n",
      "2336/2336 [==============================] - 2s 1ms/sample - loss: 4.0632e-04 - mae: 0.0160 - val_loss: 0.0013 - val_mae: 0.0321\n",
      "Epoch 4/100\n",
      "2336/2336 [==============================] - 2s 972us/sample - loss: 4.1969e-04 - mae: 0.0162 - val_loss: 7.1926e-04 - val_mae: 0.0229\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred'])\n",
    "\n",
    "\n",
    "X = lstm_train_X.drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "y = lstm_train_y.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "X_test = lstm_test_X.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "y_test = lstm_test_y.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2, shuffle=False, random_state=1004)    \n",
    "    \n",
    "\n",
    "X_train_v = X_train.values\n",
    "y_train_v = y_train.values\n",
    "\n",
    "X_valid_v = X_valid.values\n",
    "y_valid_v = y_valid.values\n",
    "\n",
    "X_test_v = X_test.values\n",
    "y_test_v = y_test.values\n",
    "\n",
    "X_train_t = X_train_v.reshape(X_train_v.shape[0], 1,X_train_v.shape[1])\n",
    "X_valid_t = X_valid_v.reshape(X_valid_v.shape[0],1,X_valid_v.shape[1])\n",
    "X_test_t = X_test_v.reshape(X_test_v.shape[0], 1,X_test_v.shape[1])\n",
    "\n",
    "\n",
    "## model\n",
    "K.clear_session() \n",
    "\n",
    "model = Sequential()\n",
    "optimizer = Adam(lr=0.01)\n",
    "model.add(LSTM(200,input_shape = (1,X_train_v.shape[1]))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "          batch_size=4, verbose=1, callbacks=[early_stop], validation_data = (X_valid_t, y_valid_v))\n",
    "##\n",
    "\n",
    "y_pred = model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = lstm_test_y.copy()\n",
    "test_pred_df['AVG_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AVG</th>\n",
       "      <th>AVG_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HH</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.288575</td>\n",
       "      <td>0.293828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.293250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.285575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>0.294314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.309893</td>\n",
       "      <td>0.291183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.287440</td>\n",
       "      <td>0.297987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OB</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.298225</td>\n",
       "      <td>0.302721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.289824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SS</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.283863</td>\n",
       "      <td>0.301495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.298354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HH</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.272944</td>\n",
       "      <td>0.293883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>0.300350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.287304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.274136</td>\n",
       "      <td>0.292204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.297794</td>\n",
       "      <td>0.293715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.329682</td>\n",
       "      <td>0.294678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.288757</td>\n",
       "      <td>0.299357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>0.285807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.289802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WO</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.294767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HH</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.290983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.300697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.286690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.268675</td>\n",
       "      <td>0.294320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.286962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.285460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OB</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.316629</td>\n",
       "      <td>0.299009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.296244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.295063</td>\n",
       "      <td>0.293187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WO</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.266908</td>\n",
       "      <td>0.298683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HH</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.291092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.264524</td>\n",
       "      <td>0.292262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.265664</td>\n",
       "      <td>0.290953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.290741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.292081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.298202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.255786</td>\n",
       "      <td>0.298707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.233207</td>\n",
       "      <td>0.290655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SS</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.279376</td>\n",
       "      <td>0.289153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WO</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.298381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HH</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.250620</td>\n",
       "      <td>0.276638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.293511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.285207</td>\n",
       "      <td>0.284444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LG</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.254524</td>\n",
       "      <td>0.296549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LT</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.286722</td>\n",
       "      <td>0.289992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NC</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.276347</td>\n",
       "      <td>0.296931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>OB</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.305718</td>\n",
       "      <td>0.295425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.254007</td>\n",
       "      <td>0.282244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.309412</td>\n",
       "      <td>0.287336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>WO</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>0.291002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       AVG  AVG_pred\n",
       "0    HH  2016  0.288575  0.293828\n",
       "1    HT  2016  0.256739  0.293250\n",
       "2    KT  2016  0.295455  0.285575\n",
       "3    LG  2016  0.296069  0.294314\n",
       "4    LT  2016  0.309893  0.291183\n",
       "5    NC  2016  0.287440  0.297987\n",
       "6    OB  2016  0.298225  0.302721\n",
       "7    SK  2016  0.305263  0.289824\n",
       "8    SS  2016  0.283863  0.301495\n",
       "9    WO  2016  0.289941  0.298354\n",
       "10   HH  2017  0.272944  0.293883\n",
       "11   HT  2017  0.294464  0.300350\n",
       "12   KT  2017  0.303592  0.287304\n",
       "13   LG  2017  0.274136  0.292204\n",
       "14   LT  2017  0.297794  0.293715\n",
       "15   NC  2017  0.329682  0.294678\n",
       "16   OB  2017  0.288757  0.299357\n",
       "17   SK  2017  0.284160  0.285807\n",
       "18   SS  2017  0.293588  0.289802\n",
       "19   WO  2017  0.276888  0.294767\n",
       "20   HH  2018  0.270758  0.290983\n",
       "21   HT  2018  0.293083  0.300697\n",
       "22   KT  2018  0.280925  0.286690\n",
       "23   LG  2018  0.268675  0.294320\n",
       "24   LT  2018  0.300691  0.286962\n",
       "25   NC  2018  0.283636  0.285460\n",
       "26   OB  2018  0.316629  0.299009\n",
       "27   SK  2018  0.275089  0.296244\n",
       "28   SS  2018  0.295063  0.293187\n",
       "29   WO  2018  0.266908  0.298683\n",
       "30   HH  2019  0.236341  0.291092\n",
       "31   HT  2019  0.264524  0.292262\n",
       "32   KT  2019  0.265664  0.290953\n",
       "33   LG  2019  0.258809  0.290741\n",
       "34   LT  2019  0.268657  0.292081\n",
       "35   NC  2019  0.255611  0.298202\n",
       "36   OB  2019  0.255786  0.298707\n",
       "37   SK  2019  0.233207  0.290655\n",
       "38   SS  2019  0.279376  0.289153\n",
       "39   WO  2019  0.260143  0.298381\n",
       "40   HH  2020  0.250620  0.276638\n",
       "41   HT  2020  0.277228  0.293511\n",
       "42   KT  2020  0.285207  0.284444\n",
       "43   LG  2020  0.254524  0.296549\n",
       "44   LT  2020  0.286722  0.289992\n",
       "45   NC  2020  0.276347  0.296931\n",
       "46   OB  2020  0.305718  0.295425\n",
       "47   SK  2020  0.254007  0.282244\n",
       "48   SS  2020  0.309412  0.287336\n",
       "49   WO  2020  0.281896  0.291002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00055090713964005"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred_df['AVG'],test_pred_df['AVG_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36805904242919807"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "tmp = test_pred_df.copy()\n",
    "# tmp['half']= 0.5\n",
    "r2_y_predict = r2_score(tmp['AVG'], tmp['AVG_pred'])\n",
    "r2_y_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
