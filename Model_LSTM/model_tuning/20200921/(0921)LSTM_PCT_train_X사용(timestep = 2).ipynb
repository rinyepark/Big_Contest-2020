{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data: augment_24group_1620.csv필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCT_lstm_train_X = pd.read_csv(\"lstmPCT/PCT_lstm_final_train_X.csv\")\n",
    "# PCT_lstm_train_y = pd.read_csv(\"lstmPCT/PCT_lstm_final_train_y.csv\")\n",
    "\n",
    "# PCT_lstm_test_X = pd.read_csv(\"lstmPCT/PCT_lstm_final_test_X.csv\")\n",
    "# PCT_lstm_test_y = pd.read_csv(\"lstmPCT/PCT_lstm_final_test_y.csv\")\n",
    "\n",
    "\n",
    "\n",
    "lstm_train_X = pd.read_csv(\"lstm_data/new_PCT_train_X.csv\")\n",
    "lstm_train_y = pd.read_csv(\"lstm_data/PCT_lstm_final_train_y.csv\")\n",
    "\n",
    "lstm_test_X = pd.read_csv(\"lstm_data/new_PCT_test_X.csv\")\n",
    "lstm_test_y = pd.read_csv(\"lstm_data/PCT_lstm_final_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = list(lstm_train_X.T_ID.unique())\n",
    "year = list(lstm_train_y.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) input shape로 변경 (row, timestep=2, feature)\n",
    "\n",
    "ex) \n",
    "timestep = 2\n",
    "\n",
    "* X_train_v 구성예시: [[1 ~ 24경기 데이터, 25 ~ 48경기 데이터], [49 ~ 72경기 데이터, 73 ~ 96경기 데이터] ]  \n",
    "X_train_v.shape >> (2,2*x)             # x: 각 24group에 대한 변수 개수\n",
    "* y_train_v 구성예시: 97 ~ 120 경기 승률\n",
    "\n",
    "=> reshape\n",
    "\n",
    "* X_train_v.shape >> (2,2,x)  # row, timestep, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성(LSTM)\n",
    "- optimizer: RMSprop -> lr(learning rate) 조절\n",
    "- LSTM: 모델이 계속 동일한 결과값이 나올 때, input 뉴런 개수를 늘려야 한다는 글을 읽고 계속 input 노드 개수를 바꿔주면서 모델 생성중\n",
    "- loss: MSE\n",
    "\n",
    "- early_stop: patience를 크게하면 과적합 되는 경우가 있어서 최대한 작게 설정해둠\n",
    "- batch_size: 모델이 계속 동일한 결과값이 나올 때, 데이터가 적어 batch size를 줄여보라는 글을 읽고 1로 설정해둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 34ms/sample - loss: 0.4810 - mae: 0.3459\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0251 - mae: 0.1505\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0257 - mae: 0.1499\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0363 - mae: 0.1691\n",
      "Epoch 00004: early stopping\n",
      "2016HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 30ms/sample - loss: 0.5928 - mae: 0.2588\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0030 - mae: 0.0453\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0032 - mae: 0.0470\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0031 - mae: 0.0469\n",
      "Epoch 00004: early stopping\n",
      "2016NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 33ms/sample - loss: 0.6237 - mae: 0.3598\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0035 - mae: 0.0420\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0034 - mae: 0.0430\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0031 - mae: 0.0410\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0036 - mae: 0.0463\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0032 - mae: 0.0441\n",
      "Epoch 00006: early stopping\n",
      "2016HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.4207 - mae: 0.2322\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0020 - mae: 0.0359\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0022 - mae: 0.0346\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0021 - mae: 0.0369\n",
      "Epoch 00004: early stopping\n",
      "2016SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 30ms/sample - loss: 0.4896 - mae: 0.2822\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0050 - mae: 0.0587\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0054 - mae: 0.0637\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0063 - mae: 0.0666 0s - loss: 0.0065 - mae: 0.06\n",
      "Epoch 00004: early stopping\n",
      "2016KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 28ms/sample - loss: 0.4599 - mae: 0.2412\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0025 - mae: 0.0376\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0024 - mae: 0.0386\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0032 - mae: 0.0440\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0026 - mae: 0.0382\n",
      "Epoch 00005: early stopping\n",
      "2016WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 35ms/sample - loss: 0.6292 - mae: 0.3402\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0035 - mae: 0.0502\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0035 - mae: 0.0501\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0038 - mae: 0.0487\n",
      "Epoch 00004: early stopping\n",
      "2016LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 30ms/sample - loss: 0.3708 - mae: 0.3015\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0110 - mae: 0.0836\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0099 - mae: 0.0845\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0121 - mae: 0.0923\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0112 - mae: 0.0867\n",
      "Epoch 00005: early stopping\n",
      "2016SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 34ms/sample - loss: 0.3206 - mae: 0.2492\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0088 - mae: 0.0812\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0094 - mae: 0.0756\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0157 - mae: 0.1067\n",
      "Epoch 00004: early stopping\n",
      "2016OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.4584 - mae: 0.2711\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0113 - mae: 0.0949\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0128 - mae: 0.0938\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0164 - mae: 0.1113\n",
      "Epoch 00004: early stopping\n",
      "2017LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.3342 - mae: 0.2579\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0093 - mae: 0.0777\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0075 - mae: 0.0685\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0077 - mae: 0.0694\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0076 - mae: 0.0670\n",
      "Epoch 00005: early stopping\n",
      "2017HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.5358 - mae: 0.2755\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0084 - mae: 0.0812\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0086 - mae: 0.0796\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0086 - mae: 0.0816\n",
      "Epoch 00004: early stopping\n",
      "2017NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.3744 - mae: 0.2601\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0062 - mae: 0.0611\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0061 - mae: 0.0610\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0063 - mae: 0.0624\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0061 - mae: 0.0622\n",
      "Epoch 00005: early stopping\n",
      "2017HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 30ms/sample - loss: 0.3716 - mae: 0.2817\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0111 - mae: 0.0879\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0121 - mae: 0.0907\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0109 - mae: 0.0889\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0094 - mae: 0.0809\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0158 - mae: 0.1030\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0106 - mae: 0.0856\n",
      "Epoch 00007: early stopping\n",
      "2017SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 31ms/sample - loss: 0.4350 - mae: 0.2981\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0240 - mae: 0.1435\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0233 - mae: 0.1427\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0238 - mae: 0.1431\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0235 - mae: 0.1406\n",
      "Epoch 00005: early stopping\n",
      "2017KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 38ms/sample - loss: 0.4019 - mae: 0.2563\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0062 - mae: 0.0699\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0061 - mae: 0.0700\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0071 - mae: 0.0723\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0092 - mae: 0.0818\n",
      "Epoch 00005: early stopping\n",
      "2017WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 31ms/sample - loss: 0.3571 - mae: 0.2770\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0050 - mae: 0.0609\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0040 - mae: 0.0548\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0041 - mae: 0.0542\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0038 - mae: 0.0531\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0036 - mae: 0.0513\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0042 - mae: 0.0497\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0045 - mae: 0.0520\n",
      "Epoch 00008: early stopping\n",
      "2017LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.3764 - mae: 0.2866\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0073 - mae: 0.0699\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0067 - mae: 0.0669\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0063 - mae: 0.0634\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0072 - mae: 0.0656\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0058 - mae: 0.0630\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0091 - mae: 0.0765\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0086 - mae: 0.0740\n",
      "Epoch 00008: early stopping\n",
      "2017SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 30ms/sample - loss: 0.2752 - mae: 0.1813\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0043 - mae: 0.0475\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0052 - mae: 0.0596\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0040 - mae: 0.0460\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0044 - mae: 0.0502\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0045 - mae: 0.0513\n",
      "Epoch 00006: early stopping\n",
      "2017OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 39ms/sample - loss: 0.4992 - mae: 0.2743\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0282 - mae: 0.1381\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0288 - mae: 0.1551\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0334 - mae: 0.1566\n",
      "Epoch 00004: early stopping\n",
      "2018LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 31ms/sample - loss: 0.4312 - mae: 0.3114\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0249 - mae: 0.1284\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0258 - mae: 0.1339\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0236 - mae: 0.1297\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0244 - mae: 0.1324\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0267 - mae: 0.1383\n",
      "Epoch 00006: early stopping\n",
      "2018HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.4612 - mae: 0.3203\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0075 - mae: 0.0742\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0066 - mae: 0.0712\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0092 - mae: 0.0821\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0074 - mae: 0.0762\n",
      "Epoch 00005: early stopping\n",
      "2018NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 33ms/sample - loss: 0.4217 - mae: 0.2565\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0076 - mae: 0.0736\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0051 - mae: 0.0546\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0041 - mae: 0.0514\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0033 - mae: 0.0479\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0022 - mae: 0.0377\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0047 - mae: 0.0604\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0077 - mae: 0.0722\n",
      "Epoch 00008: early stopping\n",
      "2018HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 46ms/sample - loss: 0.4088 - mae: 0.2420\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0038 - mae: 0.0491\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0040 - mae: 0.0542\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0045 - mae: 0.0569  - 0s 4ms/sample - loss: 0.0045 - mae: 0.0560\n",
      "Epoch 00004: early stopping\n",
      "2018SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.5203 - mae: 0.2570\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0063 - mae: 0.0659\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0054 - mae: 0.0607\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0057 - mae: 0.0617\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0055 - mae: 0.0627\n",
      "Epoch 00005: early stopping\n",
      "2018KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.5152 - mae: 0.3315\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0148 - mae: 0.1031\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0145 - mae: 0.0987\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0166 - mae: 0.1057\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0161 - mae: 0.1009\n",
      "Epoch 00005: early stopping\n",
      "2018WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.2916 - mae: 0.2556\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0057 - mae: 0.0615\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 2ms/sample - loss: 0.0065 - mae: 0.0630\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0069 - mae: 0.0687\n",
      "Epoch 00004: early stopping\n",
      "2018LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 29ms/sample - loss: 0.4359 - mae: 0.2765\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0089 - mae: 0.0778\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0112 - mae: 0.0878\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0099 - mae: 0.0776\n",
      "Epoch 00004: early stopping\n",
      "2018SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 45ms/sample - loss: 0.4585 - mae: 0.2826\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0168 - mae: 0.1065\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0187 - mae: 0.1170\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0174 - mae: 0.1149\n",
      "Epoch 00004: early stopping\n",
      "2018OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 36ms/sample - loss: 0.5621 - mae: 0.2817\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0037 - mae: 0.0494\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0036 - mae: 0.0506\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0023 - mae: 0.0380\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0017 - mae: 0.0341\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0025 - mae: 0.0393\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0023 - mae: 0.0387\n",
      "Epoch 00007: early stopping\n",
      "2019LG =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 36ms/sample - loss: 0.4384 - mae: 0.3361\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0055 - mae: 0.0590\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0051 - mae: 0.0551\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0048 - mae: 0.0557\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0048 - mae: 0.0546\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0054 - mae: 0.0607\n",
      "Epoch 00006: early stopping\n",
      "2019HH =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 43ms/sample - loss: 0.5343 - mae: 0.2511\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0034 - mae: 0.0514\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0033 - mae: 0.0506\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0031 - mae: 0.0471\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0034 - mae: 0.0492\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0035 - mae: 0.0487\n",
      "Epoch 00006: early stopping\n",
      "2019NC =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 48ms/sample - loss: 0.4883 - mae: 0.2833\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0120 - mae: 0.0931\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0146 - mae: 0.0992\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0118 - mae: 0.0946\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0100 - mae: 0.0798\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0065 - mae: 0.0710\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0095 - mae: 0.0835\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0100 - mae: 0.0845\n",
      "Epoch 00008: early stopping\n",
      "2019HT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 43ms/sample - loss: 0.4322 - mae: 0.2796\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0041 - mae: 0.0517\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0037 - mae: 0.0518\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0039 - mae: 0.0511\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0040 - mae: 0.0524\n",
      "Epoch 00005: early stopping\n",
      "2019SK =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 40ms/sample - loss: 0.2998 - mae: 0.2381\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0031 - mae: 0.0466\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0034 - mae: 0.0498\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0035 - mae: 0.0487\n",
      "Epoch 00004: early stopping\n",
      "2019KT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 4s 74ms/sample - loss: 0.7229 - mae: 0.3272\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0099 - mae: 0.0828\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0084 - mae: 0.0765\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0091 - mae: 0.0807\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 3ms/sample - loss: 0.0086 - mae: 0.0781\n",
      "Epoch 00005: early stopping\n",
      "2019WO =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 68ms/sample - loss: 0.4567 - mae: 0.2917\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0049 - mae: 0.0600\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0049 - mae: 0.0570\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0050 - mae: 0.0587\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 6ms/sample - loss: 0.0053 - mae: 0.0600\n",
      "Epoch 00005: early stopping\n",
      "2019LT =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 2s 47ms/sample - loss: 0.6193 - mae: 0.3703\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0027 - mae: 0.0400\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0025 - mae: 0.0408\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0024 - mae: 0.0405\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 6ms/sample - loss: 0.0025 - mae: 0.0388\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0033 - mae: 0.0473\n",
      "Epoch 00006: early stopping\n",
      "2019SS =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 62ms/sample - loss: 0.3030 - mae: 0.2415\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 4ms/sample - loss: 0.0018 - mae: 0.0341\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0021 - mae: 0.0362\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0022 - mae: 0.0387\n",
      "Epoch 00004: early stopping\n",
      "2019OB =======================================\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               86000     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 86,101\n",
      "Trainable params: 86,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 3s 59ms/sample - loss: 0.6002 - mae: 0.2750\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0027 - mae: 0.0408\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0029 - mae: 0.0414\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 5ms/sample - loss: 0.0033 - mae: 0.0483\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms_avg'])\n",
    "\n",
    "idx = 0\n",
    "for y in year:\n",
    "    tmp1 = lstm_train_X[lstm_train_X[\"YEAR\"] == y]\n",
    "    tmp2 = lstm_train_y[lstm_train_y[\"YEAR\"] == y]\n",
    "    tmp3 = lstm_test_X[lstm_test_X[\"YEAR\"] == y]\n",
    "    tmp4 = lstm_test_y[lstm_test_y[\"YEAR\"] == y]\n",
    "    for t in team:\n",
    "        name = '{}{}'.format(y,t)\n",
    "        print(name,\"=======================================\")\n",
    "        \n",
    "        X_train = tmp1[tmp1[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "        y_train = tmp2[tmp2[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        X_test = tmp3[tmp3[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        y_test = tmp4[tmp4[\"T_ID\"] == t].drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        \n",
    "        X_train_v = X_train.values\n",
    "        y_train_v = y_train.values\n",
    "\n",
    "        X_test_v = X_test.values\n",
    "        y_test_v = y_test.values\n",
    "        \n",
    "        X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,X_train_v.shape[1]//2)\n",
    "        X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,X_test_v.shape[1]//2)\n",
    "        \n",
    "        ## model\n",
    "        K.clear_session() \n",
    "\n",
    "        model = Sequential()\n",
    "        optimizer = Adam(lr=0.01)\n",
    "#         optimizer = RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "        model.add(LSTM(100,input_shape = (2,X_train_v.shape[1]//2))) # (timestep, feature)\n",
    "        model.add(Dense(1)) # output = 1\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "#         hist1 = model.fit(X_train_t, y_train_v, epochs=100, batch_size=1, verbose=1)\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "        hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "                  batch_size=1, verbose=1, callbacks=[early_stop])\n",
    "        ##\n",
    "        \n",
    "        model_dict[name] = model\n",
    "        hist_dict[name] = hist1\n",
    "        \n",
    "        y_pred = model.predict(X_test_t)\n",
    "        rms = sqrt(mean_squared_error(y_test_v, y_pred))\n",
    "        rms_avg = sqrt(mean_squared_error(y_test_v,[y_train.mean()[0]]))\n",
    "        \n",
    "        \n",
    "        test_pred_df.loc[idx,:] = [y,t,y_test_v.reshape(-1)[0],y_pred.reshape(-1)[0],\n",
    "                                  X_test.loc[X_test.index[0],[\"shift_PCT_1\"]][0],\n",
    "                                  X_test.loc[X_test.index[0],[\"shift_PCT_2\"]][0], rms,rms_avg]\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "test_pred_df[['y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms_avg']] = test_pred_df[['y','y_pred',\"shift_PCT_1\",\"shift_PCT_2\",'rms','rms_avg']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014447585873248719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred_df['y'],test_pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.492391</td>\n",
       "      <td>0.502580</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.079156</td>\n",
       "      <td>0.085328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.498370</td>\n",
       "      <td>0.502569</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.111347</td>\n",
       "      <td>0.112986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.508351</td>\n",
       "      <td>0.500362</td>\n",
       "      <td>0.497480</td>\n",
       "      <td>0.058370</td>\n",
       "      <td>0.062770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.505072</td>\n",
       "      <td>0.496620</td>\n",
       "      <td>0.508152</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>0.116315</td>\n",
       "      <td>0.109331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_PCT_1  shift_PCT_2       rms   rms_avg\n",
       "YEAR                                                                  \n",
       "2016  0.492391  0.502580     0.504167     0.508514  0.079156  0.085328\n",
       "2017  0.498370  0.502569     0.491848     0.521937  0.111347  0.112986\n",
       "2018  0.507971  0.508351     0.500362     0.497480  0.058370  0.062770\n",
       "2019  0.505072  0.496620     0.508152     0.495290  0.116315  0.109331"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.447471</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>0.126553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521347</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>0.031221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.601569</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.036351</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.481133</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>0.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.337599</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.045932</td>\n",
       "      <td>0.059524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.606085</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.231085</td>\n",
       "      <td>0.231293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480272</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424575</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>0.080708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578207</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.088459</td>\n",
       "      <td>0.128401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.554028</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.119245</td>\n",
       "      <td>0.076050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.404618</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.030165</td>\n",
       "      <td>0.017746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521273</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.021273</td>\n",
       "      <td>0.038265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.645636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.145636</td>\n",
       "      <td>0.118123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.427930</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.197070</td>\n",
       "      <td>0.151361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.256973</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.243027</td>\n",
       "      <td>0.279762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.493564</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.145737</td>\n",
       "      <td>0.205745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.601192</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>0.104431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.453798</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>0.082628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.666676</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.083343</td>\n",
       "      <td>0.055753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.502588</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.085922</td>\n",
       "      <td>0.043959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493398</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.036565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.477880</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>0.049357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.465926</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>0.115646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.552165</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.105812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.427518</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>0.029984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.558236</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.016569</td>\n",
       "      <td>0.022959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.496503</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.170163</td>\n",
       "      <td>0.206223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.519844</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.013794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.589450</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.003401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.540491</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.253509</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.329825</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.498347</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>0.124630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.463461</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.036539</td>\n",
       "      <td>0.029429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.635223</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.260223</td>\n",
       "      <td>0.297619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.624915</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.083248</td>\n",
       "      <td>0.033126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.612323</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.054344</td>\n",
       "      <td>0.004621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.404173</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.195840</td>\n",
       "      <td>0.187512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.393737</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.006914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.540019</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.112155</td>\n",
       "      <td>0.117310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred  shift_PCT_1  shift_PCT_2       rms  \\\n",
       "0   2016   LG  0.608696  0.447471     0.583333     0.458333  0.161224   \n",
       "1   2016   HH  0.500000  0.521347     0.500000     0.608696  0.021347   \n",
       "2   2016   NC  0.565217  0.601569     0.500000     0.541667  0.036351   \n",
       "3   2016   HT  0.458333  0.547546     0.500000     0.583333  0.089213   \n",
       "4   2016   SK  0.458333  0.481133     0.458333     0.458333  0.022799   \n",
       "5   2016   KT  0.291667  0.337599     0.333333     0.375000  0.045932   \n",
       "6   2016   WO  0.375000  0.606085     0.625000     0.666667  0.231085   \n",
       "7   2016   LT  0.500000  0.480272     0.375000     0.500000  0.019728   \n",
       "8   2016   SS  0.500000  0.424575     0.500000     0.434783  0.075425   \n",
       "9   2016   OB  0.666667  0.578207     0.666667     0.458333  0.088459   \n",
       "10  2017   LG  0.434783  0.554028     0.304348     0.652174  0.119245   \n",
       "11  2017   HH  0.434783  0.404618     0.541667     0.333333  0.030165   \n",
       "12  2017   NC  0.500000  0.521273     0.458333     0.541667  0.021273   \n",
       "13  2017   HT  0.500000  0.645636     0.500000     0.782609  0.145636   \n",
       "14  2017   SK  0.625000  0.427930     0.458333     0.416667  0.197070   \n",
       "15  2017   KT  0.500000  0.256973     0.333333     0.166667  0.243027   \n",
       "16  2017   WO  0.347826  0.493564     0.500000     0.541667  0.145737   \n",
       "17  2017   LT  0.666667  0.601192     0.750000     0.590909  0.065474   \n",
       "18  2017   SS  0.391304  0.453798     0.333333     0.454545  0.062494   \n",
       "19  2017   OB  0.583333  0.666676     0.739130     0.739130  0.083343   \n",
       "20  2018   LG  0.416667  0.502588     0.291667     0.478261  0.085922   \n",
       "21  2018   HH  0.500000  0.493398     0.416667     0.583333  0.006602   \n",
       "22  2018   NC  0.416667  0.477880     0.521739     0.416667  0.061213   \n",
       "23  2018   HT  0.541667  0.465926     0.541667     0.375000  0.075741   \n",
       "24  2018   SK  0.458333  0.552165     0.500000     0.666667  0.093831   \n",
       "25  2018   KT  0.391304  0.427518     0.416667     0.545455  0.036214   \n",
       "26  2018   WO  0.541667  0.558236     0.666667     0.458333  0.016569   \n",
       "27  2018   LT  0.666667  0.496503     0.458333     0.347826  0.170163   \n",
       "28  2018   SS  0.521739  0.519844     0.565217     0.478261  0.001895   \n",
       "29  2018   OB  0.625000  0.589450     0.625000     0.625000  0.035550   \n",
       "30  2019   LG  0.541667  0.540491     0.541667     0.500000  0.001175   \n",
       "31  2019   HH  0.583333  0.253509     0.375000     0.250000  0.329825   \n",
       "32  2019   NC  0.565217  0.498347     0.541667     0.478261  0.066871   \n",
       "33  2019   HT  0.500000  0.463461     0.478261     0.416667  0.036539   \n",
       "34  2019   SK  0.375000  0.635223     0.625000     0.708333  0.260223   \n",
       "35  2019   KT  0.541667  0.624915     0.521739     0.652174  0.083248   \n",
       "36  2019   WO  0.666667  0.612323     0.565217     0.708333  0.054344   \n",
       "37  2019   LT  0.208333  0.404173     0.391304     0.304348  0.195840   \n",
       "38  2019   SS  0.416667  0.393737     0.375000     0.434783  0.022930   \n",
       "39  2019   OB  0.652174  0.540019     0.666667     0.500000  0.112155   \n",
       "\n",
       "     rms_avg  \n",
       "0   0.126553  \n",
       "1   0.031221  \n",
       "2   0.017857  \n",
       "3   0.095238  \n",
       "4   0.040816  \n",
       "5   0.059524  \n",
       "6   0.231293  \n",
       "7   0.041667  \n",
       "8   0.080708  \n",
       "9   0.128401  \n",
       "10  0.076050  \n",
       "11  0.017746  \n",
       "12  0.038265  \n",
       "13  0.118123  \n",
       "14  0.151361  \n",
       "15  0.279762  \n",
       "16  0.205745  \n",
       "17  0.104431  \n",
       "18  0.082628  \n",
       "19  0.055753  \n",
       "20  0.043959  \n",
       "21  0.036565  \n",
       "22  0.049357  \n",
       "23  0.115646  \n",
       "24  0.105812  \n",
       "25  0.029984  \n",
       "26  0.022959  \n",
       "27  0.206223  \n",
       "28  0.013794  \n",
       "29  0.003401  \n",
       "30  0.000481  \n",
       "31  0.291667  \n",
       "32  0.124630  \n",
       "33  0.029429  \n",
       "34  0.297619  \n",
       "35  0.033126  \n",
       "36  0.004621  \n",
       "37  0.187512  \n",
       "38  0.006914  \n",
       "39  0.117310  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2894852038988944"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "tmp = test_pred_df.copy()\n",
    "# tmp['half']= 0.5\n",
    "r2_y_predict = r2_score(tmp['y'], tmp['y_pred'])\n",
    "r2_y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +======================================+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.522544</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.086151</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.510781</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.543209</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.577802</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.119468</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.522475</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.064141</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.328833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.600633</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.225633</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470777</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.029223</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.440369</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.059631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.537850</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.128817</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.461004</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.379429</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498975</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.505057</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.119943</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.206646</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.293354</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.577420</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.229594</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.491583</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.175083</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.492729</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.101425</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.566920</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.444207</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.027540</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.574532</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.440569</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.435152</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.106515</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.568434</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.406778</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.015473</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.514372</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.457512</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.209154</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.532034</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.010295</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.641725</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.485760</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055907</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.302395</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.280938</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.468876</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.096342</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.478172</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.021828</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.711183</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.336183</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.565580</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.023914</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684416</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.017749</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.423814</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.215481</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.441931</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.549938</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.102236</td>\n",
       "      <td>0.152174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred  shift_PCT_1  shift_PCT_2       rms  \\\n",
       "0   2016   LG  0.608696  0.522544     0.583333     0.458333  0.086151   \n",
       "1   2016   HH  0.500000  0.510781     0.500000     0.608696  0.010781   \n",
       "2   2016   NC  0.565217  0.543209     0.500000     0.541667  0.022008   \n",
       "3   2016   HT  0.458333  0.577802     0.500000     0.583333  0.119468   \n",
       "4   2016   SK  0.458333  0.522475     0.458333     0.458333  0.064141   \n",
       "5   2016   KT  0.291667  0.328833     0.333333     0.375000  0.037166   \n",
       "6   2016   WO  0.375000  0.600633     0.625000     0.666667  0.225633   \n",
       "7   2016   LT  0.500000  0.470777     0.375000     0.500000  0.029223   \n",
       "8   2016   SS  0.500000  0.440369     0.500000     0.434783  0.059631   \n",
       "9   2016   OB  0.666667  0.537850     0.666667     0.458333  0.128817   \n",
       "10  2017   LG  0.434783  0.461004     0.304348     0.652174  0.026221   \n",
       "11  2017   HH  0.434783  0.379429     0.541667     0.333333  0.055354   \n",
       "12  2017   NC  0.500000  0.498975     0.458333     0.541667  0.001025   \n",
       "13  2017   HT  0.500000  0.594801     0.500000     0.782609  0.094801   \n",
       "14  2017   SK  0.625000  0.505057     0.458333     0.416667  0.119943   \n",
       "15  2017   KT  0.500000  0.206646     0.333333     0.166667  0.293354   \n",
       "16  2017   WO  0.347826  0.577420     0.500000     0.541667  0.229594   \n",
       "17  2017   LT  0.666667  0.491583     0.750000     0.590909  0.175083   \n",
       "18  2017   SS  0.391304  0.492729     0.333333     0.454545  0.101425   \n",
       "19  2017   OB  0.583333  0.566920     0.739130     0.739130  0.016413   \n",
       "20  2018   LG  0.416667  0.444207     0.291667     0.478261  0.027540   \n",
       "21  2018   HH  0.500000  0.574532     0.416667     0.583333  0.074532   \n",
       "22  2018   NC  0.416667  0.440569     0.521739     0.416667  0.023902   \n",
       "23  2018   HT  0.541667  0.435152     0.541667     0.375000  0.106515   \n",
       "24  2018   SK  0.458333  0.568434     0.500000     0.666667  0.110100   \n",
       "25  2018   KT  0.391304  0.406778     0.416667     0.545455  0.015473   \n",
       "26  2018   WO  0.541667  0.514372     0.666667     0.458333  0.027295   \n",
       "27  2018   LT  0.666667  0.457512     0.458333     0.347826  0.209154   \n",
       "28  2018   SS  0.521739  0.532034     0.565217     0.478261  0.010295   \n",
       "29  2018   OB  0.625000  0.641725     0.625000     0.625000  0.016725   \n",
       "30  2019   LG  0.541667  0.485760     0.541667     0.500000  0.055907   \n",
       "31  2019   HH  0.583333  0.302395     0.375000     0.250000  0.280938   \n",
       "32  2019   NC  0.565217  0.468876     0.541667     0.478261  0.096342   \n",
       "33  2019   HT  0.500000  0.478172     0.478261     0.416667  0.021828   \n",
       "34  2019   SK  0.375000  0.711183     0.625000     0.708333  0.336183   \n",
       "35  2019   KT  0.541667  0.565580     0.521739     0.652174  0.023914   \n",
       "36  2019   WO  0.666667  0.684416     0.565217     0.708333  0.017749   \n",
       "37  2019   LT  0.208333  0.423814     0.391304     0.304348  0.215481   \n",
       "38  2019   SS  0.416667  0.441931     0.375000     0.434783  0.025264   \n",
       "39  2019   OB  0.652174  0.549938     0.666667     0.500000  0.102236   \n",
       "\n",
       "      rms0.5  \n",
       "0   0.108696  \n",
       "1   0.000000  \n",
       "2   0.065217  \n",
       "3   0.041667  \n",
       "4   0.041667  \n",
       "5   0.208333  \n",
       "6   0.125000  \n",
       "7   0.000000  \n",
       "8   0.000000  \n",
       "9   0.166667  \n",
       "10  0.065217  \n",
       "11  0.065217  \n",
       "12  0.000000  \n",
       "13  0.000000  \n",
       "14  0.125000  \n",
       "15  0.000000  \n",
       "16  0.152174  \n",
       "17  0.166667  \n",
       "18  0.108696  \n",
       "19  0.083333  \n",
       "20  0.083333  \n",
       "21  0.000000  \n",
       "22  0.083333  \n",
       "23  0.041667  \n",
       "24  0.041667  \n",
       "25  0.108696  \n",
       "26  0.041667  \n",
       "27  0.166667  \n",
       "28  0.021739  \n",
       "29  0.125000  \n",
       "30  0.041667  \n",
       "31  0.083333  \n",
       "32  0.065217  \n",
       "33  0.000000  \n",
       "34  0.125000  \n",
       "35  0.041667  \n",
       "36  0.166667  \n",
       "37  0.291667  \n",
       "38  0.083333  \n",
       "39  0.152174  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #100, lr = 0.01, patience 2 +++, rms ver, rms05 ver, Adam, batch2\n",
    "\n",
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.492391</td>\n",
       "      <td>0.505527</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.508514</td>\n",
       "      <td>0.078302</td>\n",
       "      <td>0.075725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.498370</td>\n",
       "      <td>0.477456</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.521937</td>\n",
       "      <td>0.111321</td>\n",
       "      <td>0.076630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.507971</td>\n",
       "      <td>0.501531</td>\n",
       "      <td>0.500362</td>\n",
       "      <td>0.497480</td>\n",
       "      <td>0.062153</td>\n",
       "      <td>0.071377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.505072</td>\n",
       "      <td>0.511206</td>\n",
       "      <td>0.508152</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>0.117584</td>\n",
       "      <td>0.105072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y    y_pred  shift_PCT_1  shift_PCT_2       rms    rms0.5\n",
       "YEAR                                                                  \n",
       "2016  0.492391  0.505527     0.504167     0.508514  0.078302  0.075725\n",
       "2017  0.498370  0.477456     0.491848     0.521937  0.111321  0.076630\n",
       "2018  0.507971  0.501531     0.500362     0.497480  0.062153  0.071377\n",
       "2019  0.505072  0.511206     0.508152     0.495290  0.117584  0.105072"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df.groupby([\"YEAR\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.468182</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.567216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.492161</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.468182    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.567216         0.5    0.608696\n",
       "2  2016   NC  0.565217  0.492161         0.5    0.541667"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #300, lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.423421</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.479113</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.423421    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.479113         0.5    0.608696"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #300, lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.490298</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.672277</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.653289</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.490298    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.672277         0.5    0.608696\n",
       "2  2016   NC  0.565217  0.653289         0.5    0.541667"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #300, lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>2.45143</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-2.15025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>-1.5099</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y   y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  2.45143    0.583333    0.458333\n",
       "1  2016   HH       0.5 -2.15025         0.5    0.608696\n",
       "2  2016   NC  0.565217  -1.5099         0.5    0.541667"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.46766</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.554741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.540454</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.586706</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.492073</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.450251</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.629395</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.417594</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.488712</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.553688</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.565867</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.31171</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.487845</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.464065</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.377638</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.204735</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0   2016   LG  0.608696   0.46766    0.583333    0.458333\n",
       "1   2016   HH       0.5  0.554741         0.5    0.608696\n",
       "2   2016   NC  0.565217  0.540454         0.5    0.541667\n",
       "3   2016   HT  0.458333  0.586706         0.5    0.583333\n",
       "4   2016   SK  0.458333  0.492073    0.458333    0.458333\n",
       "5   2016   KT  0.291667  0.450251    0.333333       0.375\n",
       "6   2016   WO     0.375  0.629395       0.625    0.666667\n",
       "7   2016   LT       0.5  0.417594       0.375         0.5\n",
       "8   2016   SS       0.5  0.488712         0.5    0.434783\n",
       "9   2016   OB  0.666667  0.553688    0.666667    0.458333\n",
       "10  2017   LG  0.434783  0.565867    0.304348    0.652174\n",
       "11  2017   HH  0.434783   0.31171    0.541667    0.333333\n",
       "12  2017   NC       0.5  0.487845    0.458333    0.541667\n",
       "13  2017   HT       0.5  0.464065         0.5    0.782609\n",
       "14  2017   SK     0.625  0.377638    0.458333    0.416667\n",
       "15  2017   KT       0.5  0.204735    0.333333    0.166667"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01, patience 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.477605</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.509489</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.519098</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.585744</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.462029</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.333392</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.543434</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.377705</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400355</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.539122</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.500583</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.435981</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.498783</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0   2016   LG  0.608696  0.477605    0.583333    0.458333\n",
       "1   2016   HH       0.5  0.509489         0.5    0.608696\n",
       "2   2016   NC  0.565217  0.519098         0.5    0.541667\n",
       "3   2016   HT  0.458333  0.585744         0.5    0.583333\n",
       "4   2016   SK  0.458333  0.462029    0.458333    0.458333\n",
       "5   2016   KT  0.291667  0.333392    0.333333       0.375\n",
       "6   2016   WO     0.375  0.543434       0.625    0.666667\n",
       "7   2016   LT       0.5  0.377705       0.375         0.5\n",
       "8   2016   SS       0.5  0.400355         0.5    0.434783\n",
       "9   2016   OB  0.666667  0.539122    0.666667    0.458333\n",
       "10  2017   LG  0.434783  0.500583    0.304348    0.652174\n",
       "11  2017   HH  0.434783  0.435981    0.541667    0.333333\n",
       "12  2017   NC       0.5  0.498783    0.458333    0.541667"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01, patience 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.506664</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.102032</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.518261</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.0182612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.520184</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0450339</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.562111</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.103777</td>\n",
       "      <td>0.0416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.487501</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0291681</td>\n",
       "      <td>0.0416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.372884</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0812176</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.203908</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.431082</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0689185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4259</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0740999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.496237</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.170429</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.468442</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0336597</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.455786</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0210039</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.531187</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0311873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2        rms  \\\n",
       "0   2016   LG  0.608696  0.506664    0.583333    0.458333   0.102032   \n",
       "1   2016   HH       0.5  0.518261         0.5    0.608696  0.0182612   \n",
       "2   2016   NC  0.565217  0.520184         0.5    0.541667  0.0450339   \n",
       "3   2016   HT  0.458333  0.562111         0.5    0.583333   0.103777   \n",
       "4   2016   SK  0.458333  0.487501    0.458333    0.458333  0.0291681   \n",
       "5   2016   KT  0.291667  0.372884    0.333333       0.375  0.0812176   \n",
       "6   2016   WO     0.375  0.578908       0.625    0.666667   0.203908   \n",
       "7   2016   LT       0.5  0.431082       0.375         0.5  0.0689185   \n",
       "8   2016   SS       0.5    0.4259         0.5    0.434783  0.0740999   \n",
       "9   2016   OB  0.666667  0.496237    0.666667    0.458333   0.170429   \n",
       "10  2017   LG  0.434783  0.468442    0.304348    0.652174  0.0336597   \n",
       "11  2017   HH  0.434783  0.455786    0.541667    0.333333  0.0210039   \n",
       "12  2017   NC       0.5  0.531187    0.458333    0.541667  0.0311873   \n",
       "\n",
       "       rms0.5  \n",
       "0    0.108696  \n",
       "1           0  \n",
       "2   0.0652174  \n",
       "3   0.0416667  \n",
       "4   0.0416667  \n",
       "5    0.208333  \n",
       "6       0.125  \n",
       "7           0  \n",
       "8           0  \n",
       "9    0.166667  \n",
       "10  0.0652174  \n",
       "11  0.0652174  \n",
       "12          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #100, lr = 0.01, patience 2 +++, rms ver, rms05 ver, Adam\n",
    "\n",
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "      <th>rms0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.612487</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.00379184</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434664</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.0653357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.529742</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0354756</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.542623</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0842892</td>\n",
       "      <td>0.0416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.442084</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0162496</td>\n",
       "      <td>0.0416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0586392</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.586355</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.211355</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.475668</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0243322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.475334</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.024666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.537623</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.129044</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.519807</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0850246</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.367407</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0673759</td>\n",
       "      <td>0.0652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.489935</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0100647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.508418</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.00841796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.745366</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.120366</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.236669</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.263331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2         rms  \\\n",
       "0   2016   LG  0.608696  0.612487    0.583333    0.458333  0.00379184   \n",
       "1   2016   HH       0.5  0.434664         0.5    0.608696   0.0653357   \n",
       "2   2016   NC  0.565217  0.529742         0.5    0.541667   0.0354756   \n",
       "3   2016   HT  0.458333  0.542623         0.5    0.583333   0.0842892   \n",
       "4   2016   SK  0.458333  0.442084    0.458333    0.458333   0.0162496   \n",
       "5   2016   KT  0.291667  0.350306    0.333333       0.375   0.0586392   \n",
       "6   2016   WO     0.375  0.586355       0.625    0.666667    0.211355   \n",
       "7   2016   LT       0.5  0.475668       0.375         0.5   0.0243322   \n",
       "8   2016   SS       0.5  0.475334         0.5    0.434783    0.024666   \n",
       "9   2016   OB  0.666667  0.537623    0.666667    0.458333    0.129044   \n",
       "10  2017   LG  0.434783  0.519807    0.304348    0.652174   0.0850246   \n",
       "11  2017   HH  0.434783  0.367407    0.541667    0.333333   0.0673759   \n",
       "12  2017   NC       0.5  0.489935    0.458333    0.541667   0.0100647   \n",
       "13  2017   HT       0.5  0.508418         0.5    0.782609  0.00841796   \n",
       "14  2017   SK     0.625  0.745366    0.458333    0.416667    0.120366   \n",
       "15  2017   KT       0.5  0.236669    0.333333    0.166667    0.263331   \n",
       "\n",
       "       rms0.5  \n",
       "0    0.108696  \n",
       "1           0  \n",
       "2   0.0652174  \n",
       "3   0.0416667  \n",
       "4   0.0416667  \n",
       "5    0.208333  \n",
       "6       0.125  \n",
       "7           0  \n",
       "8           0  \n",
       "9    0.166667  \n",
       "10  0.0652174  \n",
       "11  0.0652174  \n",
       "12          0  \n",
       "13          0  \n",
       "14      0.125  \n",
       "15          0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #100, lr = 0.01, patience 2 +++, rms ver, rms05 ver\n",
    "# model_copy = model_dict.copy()\n",
    "# hist_copy = hist_dict.copy()\n",
    "# tmp_df = test_pred_df.copy()\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "      <th>rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.287378</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.321318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.582811</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.0828107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.587976</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0227588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0845234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.453548</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.00478577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0406745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.544543</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.169543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.41319</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0868104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434083</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0659173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.746169</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.0795019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.624149</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.189366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.45127</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0164875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.512952</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.0129524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.510027</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.0100266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.530251</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0947489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.212517</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.287483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.564185</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.216359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.56739</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.0992771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.708846</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.317542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583036</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.000297268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.401941</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.0147252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.502967</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.00296724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.596969</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.180302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.41666</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.525472</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0671387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.400999</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.00969421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.426227</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.115439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.315825</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.205914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.592308</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.0326918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.432563</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.109104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.273628</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.309706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2          rms\n",
       "0   2016   LG  0.608696  0.287378    0.583333    0.458333     0.321318\n",
       "1   2016   HH       0.5  0.582811         0.5    0.608696    0.0828107\n",
       "2   2016   NC  0.565217  0.587976         0.5    0.541667    0.0227588\n",
       "3   2016   HT  0.458333  0.542857         0.5    0.583333    0.0845234\n",
       "4   2016   SK  0.458333  0.453548    0.458333    0.458333   0.00478577\n",
       "5   2016   KT  0.291667  0.332341    0.333333       0.375    0.0406745\n",
       "6   2016   WO     0.375  0.544543       0.625    0.666667     0.169543\n",
       "7   2016   LT       0.5   0.41319       0.375         0.5    0.0868104\n",
       "8   2016   SS       0.5  0.434083         0.5    0.434783    0.0659173\n",
       "9   2016   OB  0.666667  0.746169    0.666667    0.458333    0.0795019\n",
       "10  2017   LG  0.434783  0.624149    0.304348    0.652174     0.189366\n",
       "11  2017   HH  0.434783   0.45127    0.541667    0.333333    0.0164875\n",
       "12  2017   NC       0.5  0.512952    0.458333    0.541667    0.0129524\n",
       "13  2017   HT       0.5  0.510027         0.5    0.782609    0.0100266\n",
       "14  2017   SK     0.625  0.530251    0.458333    0.416667    0.0947489\n",
       "15  2017   KT       0.5  0.212517    0.333333    0.166667     0.287483\n",
       "16  2017   WO  0.347826  0.564185         0.5    0.541667     0.216359\n",
       "17  2017   LT  0.666667   0.56739        0.75    0.590909    0.0992771\n",
       "18  2017   SS  0.391304  0.708846    0.333333    0.454545     0.317542\n",
       "19  2017   OB  0.583333  0.583036     0.73913     0.73913  0.000297268\n",
       "20  2018   LG  0.416667  0.401941    0.291667    0.478261    0.0147252\n",
       "21  2018   HH       0.5  0.502967    0.416667    0.583333   0.00296724\n",
       "22  2018   NC  0.416667  0.596969    0.521739    0.416667     0.180302\n",
       "23  2018   HT  0.541667   0.41666    0.541667       0.375     0.125006\n",
       "24  2018   SK  0.458333  0.525472         0.5    0.666667    0.0671387\n",
       "25  2018   KT  0.391304  0.400999    0.416667    0.545455   0.00969421\n",
       "26  2018   WO  0.541667  0.426227    0.666667    0.458333     0.115439\n",
       "27  2018   LT  0.666667  0.380567    0.458333    0.347826       0.2861\n",
       "28  2018   SS  0.521739  0.315825    0.565217    0.478261     0.205914\n",
       "29  2018   OB     0.625  0.592308       0.625       0.625    0.0326918\n",
       "30  2019   LG  0.541667  0.432563    0.541667         0.5     0.109104\n",
       "31  2019   HH  0.583333  0.273628       0.375        0.25     0.309706"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01, patience 2 +++, rms ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.435018</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.534284</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.626261</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.544398</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.556326</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.670688</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.443552</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.401195</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.483709</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.484057</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.458554</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416243</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.579688</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.45835</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.517082</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.498034</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.44207</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.549855</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.73913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.589958</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.458646</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.537073</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.457525</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.566216</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428455</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.613215</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.59965</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.521697</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.261827</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.567362</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.442509</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.705648</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.593616</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678757</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.389316</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0   2016   LG  0.608696  0.435018    0.583333    0.458333\n",
       "1   2016   HH       0.5  0.534284         0.5    0.608696\n",
       "2   2016   NC  0.565217  0.626261         0.5    0.541667\n",
       "3   2016   HT  0.458333  0.544398         0.5    0.583333\n",
       "4   2016   SK  0.458333  0.556326    0.458333    0.458333\n",
       "5   2016   KT  0.291667  0.371262    0.333333       0.375\n",
       "6   2016   WO     0.375  0.670688       0.625    0.666667\n",
       "7   2016   LT       0.5  0.443552       0.375         0.5\n",
       "8   2016   SS       0.5  0.401195         0.5    0.434783\n",
       "9   2016   OB  0.666667  0.483709    0.666667    0.458333\n",
       "10  2017   LG  0.434783  0.484057    0.304348    0.652174\n",
       "11  2017   HH  0.434783  0.458554    0.541667    0.333333\n",
       "12  2017   NC       0.5  0.416243    0.458333    0.541667\n",
       "13  2017   HT       0.5  0.579688         0.5    0.782609\n",
       "14  2017   SK     0.625   0.45835    0.458333    0.416667\n",
       "15  2017   KT       0.5   0.25805    0.333333    0.166667\n",
       "16  2017   WO  0.347826  0.517082         0.5    0.541667\n",
       "17  2017   LT  0.666667  0.498034        0.75    0.590909\n",
       "18  2017   SS  0.391304   0.44207    0.333333    0.454545\n",
       "19  2017   OB  0.583333  0.549855     0.73913     0.73913\n",
       "20  2018   LG  0.416667  0.401864    0.291667    0.478261\n",
       "21  2018   HH       0.5  0.589958    0.416667    0.583333\n",
       "22  2018   NC  0.416667  0.363228    0.521739    0.416667\n",
       "23  2018   HT  0.541667  0.458646    0.541667       0.375\n",
       "24  2018   SK  0.458333  0.537073         0.5    0.666667\n",
       "25  2018   KT  0.391304  0.457525    0.416667    0.545455\n",
       "26  2018   WO  0.541667  0.566216    0.666667    0.458333\n",
       "27  2018   LT  0.666667  0.428455    0.458333    0.347826\n",
       "28  2018   SS  0.521739  0.613215    0.565217    0.478261\n",
       "29  2018   OB     0.625   0.59965       0.625       0.625\n",
       "30  2019   LG  0.541667  0.521697    0.541667         0.5\n",
       "31  2019   HH  0.583333  0.261827       0.375        0.25\n",
       "32  2019   NC  0.565217  0.567362    0.541667    0.478261\n",
       "33  2019   HT       0.5  0.442509    0.478261    0.416667\n",
       "34  2019   SK     0.375  0.705648       0.625    0.708333\n",
       "35  2019   KT  0.541667  0.593616    0.521739    0.652174\n",
       "36  2019   WO  0.666667  0.678757    0.565217    0.708333\n",
       "37  2019   LT  0.208333  0.389316    0.391304    0.304348"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01, patience 2 ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.288105</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.504434</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.539863</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.548684</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.418596</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.35347</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.663121</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.495439</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.383013</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.541724</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.475225</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0   2016   LG  0.608696  0.288105    0.583333    0.458333\n",
       "1   2016   HH       0.5  0.504434         0.5    0.608696\n",
       "2   2016   NC  0.565217  0.539863         0.5    0.541667\n",
       "3   2016   HT  0.458333  0.548684         0.5    0.583333\n",
       "4   2016   SK  0.458333  0.418596    0.458333    0.458333\n",
       "5   2016   KT  0.291667   0.35347    0.333333       0.375\n",
       "6   2016   WO     0.375  0.663121       0.625    0.666667\n",
       "7   2016   LT       0.5  0.495439       0.375         0.5\n",
       "8   2016   SS       0.5  0.383013         0.5    0.434783\n",
       "9   2016   OB  0.666667  0.541724    0.666667    0.458333\n",
       "10  2017   LG  0.434783    0.4588    0.304348    0.652174\n",
       "11  2017   HH  0.434783  0.475225    0.541667    0.333333"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01, patience 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.467328</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.527652</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.52047</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.429098</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.467328    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.527652         0.5    0.608696\n",
       "2  2016   NC  0.565217   0.52047         0.5    0.541667\n",
       "3  2016   HT  0.458333  0.429098         0.5    0.583333\n",
       "4  2016   SK  0.458333    0.4829    0.458333    0.458333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.542802</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.545997</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.567216</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.577572</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.604854</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.42159</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.598227</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.386472</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.329622</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.542802    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.545997         0.5    0.608696\n",
       "2  2016   NC  0.565217  0.567216         0.5    0.541667\n",
       "3  2016   HT  0.458333  0.577572         0.5    0.583333\n",
       "4  2016   SK  0.458333  0.604854    0.458333    0.458333\n",
       "5  2016   KT  0.291667   0.42159    0.333333       0.375\n",
       "6  2016   WO     0.375  0.598227       0.625    0.666667\n",
       "7  2016   LT       0.5  0.386472       0.375         0.5\n",
       "8  2016   SS       0.5  0.329622         0.5    0.434783"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.478348</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.529292</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.478348    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.529292         0.5    0.608696"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.494715</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.630847</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.489612</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.593727</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.523688</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.243116</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.637864</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400517</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.494715    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.630847         0.5    0.608696\n",
       "2  2016   NC  0.565217  0.489612         0.5    0.541667\n",
       "3  2016   HT  0.458333  0.593727         0.5    0.583333\n",
       "4  2016   SK  0.458333  0.523688    0.458333    0.458333\n",
       "5  2016   KT  0.291667  0.243116    0.333333       0.375\n",
       "6  2016   WO     0.375  0.637864       0.625    0.666667\n",
       "7  2016   LT       0.5  0.400517       0.375         0.5\n",
       "8  2016   SS       0.5  0.314818         0.5    0.434783"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #100, lr=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.545502</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.607057</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.607852</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>SK</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.419407</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>KT</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.42172</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>WO</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.52766</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>LT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.30456</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>SS</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.501613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>OB</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.591436</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.441216</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.444414</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0   2016   LG  0.608696  0.545502    0.583333    0.458333\n",
       "1   2016   HH       0.5  0.636396         0.5    0.608696\n",
       "2   2016   NC  0.565217  0.607057         0.5    0.541667\n",
       "3   2016   HT  0.458333  0.607852         0.5    0.583333\n",
       "4   2016   SK  0.458333  0.419407    0.458333    0.458333\n",
       "5   2016   KT  0.291667   0.42172    0.333333       0.375\n",
       "6   2016   WO     0.375   0.52766       0.625    0.666667\n",
       "7   2016   LT       0.5   0.30456       0.375         0.5\n",
       "8   2016   SS       0.5  0.501613         0.5    0.434783\n",
       "9   2016   OB  0.666667  0.591436    0.666667    0.458333\n",
       "10  2017   LG  0.434783  0.441216    0.304348    0.652174\n",
       "11  2017   HH  0.434783  0.444414    0.541667    0.333333"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #200, lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.392572</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.548009</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.392572    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.548009         0.5    0.608696"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #200, lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>T_ID</th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>shift_PCT_1</th>\n",
       "      <th>shift_PCT_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>LG</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.513151</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.573316</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>NC</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.635897</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>HT</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.470724</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR T_ID         y    y_pred shift_PCT_1 shift_PCT_2\n",
       "0  2016   LG  0.608696  0.513151    0.583333    0.458333\n",
       "1  2016   HH       0.5  0.573316         0.5    0.608696\n",
       "2  2016   NC  0.565217  0.635897         0.5    0.541667\n",
       "3  2016   HT  0.458333  0.470724         0.5    0.583333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df #200, lr=0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist1.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist1.history['mae'], 'b', label='train mae')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('mae')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
