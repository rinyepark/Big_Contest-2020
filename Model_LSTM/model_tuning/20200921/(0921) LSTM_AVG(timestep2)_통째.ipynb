{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data: augment_24group_1620.csv필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_X = pd.read_csv(\"lstm_data/new_AVG_train_X.csv\")\n",
    "lstm_train_y = pd.read_csv(\"lstm_data/AVG_lstm_final_train_y.csv\")\n",
    "\n",
    "lstm_test_X = pd.read_csv(\"lstm_data/new_AVG_test_X.csv\")\n",
    "lstm_test_y = pd.read_csv(\"lstm_data/AVG_lstm_final_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = list(lstm_train_X.T_ID.unique())\n",
    "year = list(lstm_train_y.YEAR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB'],\n",
       " [2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team, year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) input shape로 변경 (row, timestep=2, feature)\n",
    "\n",
    "ex) \n",
    "timestep = 2\n",
    "\n",
    "* X_train_v 구성예시: [[1 ~ 24경기 데이터, 25 ~ 48경기 데이터], [49 ~ 72경기 데이터, 73 ~ 96경기 데이터] ]  \n",
    "X_train_v.shape >> (2,2*x)             # x: 각 24group에 대한 변수 개수\n",
    "* y_train_v 구성예시: 97 ~ 120 경기 승률\n",
    "\n",
    "=> reshape\n",
    "\n",
    "* X_train_v.shape >> (2,2,x)  # row, timestep, feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 구성(LSTM)\n",
    "- optimizer: RMSprop -> lr(learning rate) 조절\n",
    "- LSTM: 모델이 계속 동일한 결과값이 나올 때, input 뉴런 개수를 늘려야 한다는 글을 읽고 계속 input 노드 개수를 바꿔주면서 모델 생성중\n",
    "- loss: MSE\n",
    "\n",
    "- early_stop: patience를 크게하면 과적합 되는 경우가 있어서 최대한 작게 설정해둠\n",
    "- batch_size: 모델이 계속 동일한 결과값이 나올 때, 데이터가 적어 batch size를 줄여보라는 글을 읽고 1로 설정해둠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:red\"> MSE로 통일했습니다! </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               77200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 77,301\n",
      "Trainable params: 77,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1568 samples, validate on 392 samples\n",
      "Epoch 1/100\n",
      "1568/1568 [==============================] - 8s 5ms/sample - loss: 0.0140 - mae: 0.0295 - val_loss: 9.1719e-04 - val_mae: 0.0271\n",
      "Epoch 2/100\n",
      "1568/1568 [==============================] - 6s 4ms/sample - loss: 8.9396e-04 - mae: 0.0236 - val_loss: 6.0547e-04 - val_mae: 0.0209\n",
      "Epoch 3/100\n",
      "1568/1568 [==============================] - 6s 4ms/sample - loss: 0.0010 - mae: 0.0254 - val_loss: 8.1757e-04 - val_mae: 0.0253\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_dict = dict()\n",
    "hist_dict = dict()\n",
    "test_pred_df = pd.DataFrame([],columns = ['YEAR','T_ID','y','y_pred'])\n",
    "\n",
    "\n",
    "X = lstm_train_X.drop([\"T_ID\",\"YEAR\"],axis = 1)\n",
    "y = lstm_train_y.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "X_test = lstm_test_X.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "y_test = lstm_test_y.drop([\"T_ID\",\"YEAR\"],axis=1)\n",
    "        \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2, shuffle=False, random_state=1004)    \n",
    "    \n",
    "\n",
    "X_train_v = X_train.values\n",
    "y_train_v = y_train.values\n",
    "\n",
    "X_valid_v = X_valid.values\n",
    "y_valid_v = y_valid.values\n",
    "\n",
    "X_test_v = X_test.values\n",
    "y_test_v = y_test.values\n",
    "\n",
    "X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,X_train_v.shape[1]//2)\n",
    "X_valid_t = X_valid_v.reshape(X_valid_v.shape[0],2,X_valid_v.shape[1]//2)\n",
    "X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,X_test_v.shape[1]//2)\n",
    "\n",
    "\n",
    "## model\n",
    "K.clear_session() \n",
    "\n",
    "model = Sequential()\n",
    "optimizer = Adam(lr=0.01)\n",
    "model.add(LSTM(100,input_shape = (2,X_train_v.shape[1]//2))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode = 'min',patience=1, verbose=1)\n",
    "\n",
    "hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "          batch_size=1, verbose=1, callbacks=[early_stop], validation_data = (X_valid_t, y_valid_v))\n",
    "##\n",
    "\n",
    "y_pred = model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = lstm_test_y.copy()\n",
    "test_pred_df['AVG_pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AVG</th>\n",
       "      <th>AVG_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HH</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.288575</td>\n",
       "      <td>0.293127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.256739</td>\n",
       "      <td>0.293249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.292774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>0.293146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.309893</td>\n",
       "      <td>0.293086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NC</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.287440</td>\n",
       "      <td>0.293289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OB</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.298225</td>\n",
       "      <td>0.293318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.305263</td>\n",
       "      <td>0.293045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SS</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.283863</td>\n",
       "      <td>0.293288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WO</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.289941</td>\n",
       "      <td>0.293276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HH</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.272944</td>\n",
       "      <td>0.293057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>0.293381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.303592</td>\n",
       "      <td>0.292474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LG</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.274136</td>\n",
       "      <td>0.292835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LT</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.297794</td>\n",
       "      <td>0.292963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NC</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.329682</td>\n",
       "      <td>0.293128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OB</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.288757</td>\n",
       "      <td>0.293343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>0.293063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SS</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.293588</td>\n",
       "      <td>0.292827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WO</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.276888</td>\n",
       "      <td>0.293138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HH</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.292829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.293083</td>\n",
       "      <td>0.293263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.292984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LG</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.268675</td>\n",
       "      <td>0.293124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LT</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.300691</td>\n",
       "      <td>0.293135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.283636</td>\n",
       "      <td>0.292580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OB</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.316629</td>\n",
       "      <td>0.293324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.293212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SS</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.295063</td>\n",
       "      <td>0.293033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>WO</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.266908</td>\n",
       "      <td>0.293212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HH</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.236341</td>\n",
       "      <td>0.292538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.264524</td>\n",
       "      <td>0.292769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.265664</td>\n",
       "      <td>0.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LG</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.292811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LT</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.292434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NC</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.293007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OB</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.255786</td>\n",
       "      <td>0.293046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.233207</td>\n",
       "      <td>0.292942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SS</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.279376</td>\n",
       "      <td>0.292668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>WO</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>0.293207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       AVG  AVG_pred\n",
       "0    HH  2016  0.288575  0.293127\n",
       "1    HT  2016  0.256739  0.293249\n",
       "2    KT  2016  0.295455  0.292774\n",
       "3    LG  2016  0.296069  0.293146\n",
       "4    LT  2016  0.309893  0.293086\n",
       "5    NC  2016  0.287440  0.293289\n",
       "6    OB  2016  0.298225  0.293318\n",
       "7    SK  2016  0.305263  0.293045\n",
       "8    SS  2016  0.283863  0.293288\n",
       "9    WO  2016  0.289941  0.293276\n",
       "10   HH  2017  0.272944  0.293057\n",
       "11   HT  2017  0.294464  0.293381\n",
       "12   KT  2017  0.303592  0.292474\n",
       "13   LG  2017  0.274136  0.292835\n",
       "14   LT  2017  0.297794  0.292963\n",
       "15   NC  2017  0.329682  0.293128\n",
       "16   OB  2017  0.288757  0.293343\n",
       "17   SK  2017  0.284160  0.293063\n",
       "18   SS  2017  0.293588  0.292827\n",
       "19   WO  2017  0.276888  0.293138\n",
       "20   HH  2018  0.270758  0.292829\n",
       "21   HT  2018  0.293083  0.293263\n",
       "22   KT  2018  0.280925  0.292984\n",
       "23   LG  2018  0.268675  0.293124\n",
       "24   LT  2018  0.300691  0.293135\n",
       "25   NC  2018  0.283636  0.292580\n",
       "26   OB  2018  0.316629  0.293324\n",
       "27   SK  2018  0.275089  0.293212\n",
       "28   SS  2018  0.295063  0.293033\n",
       "29   WO  2018  0.266908  0.293212\n",
       "30   HH  2019  0.236341  0.292538\n",
       "31   HT  2019  0.264524  0.292769\n",
       "32   KT  2019  0.265664  0.292900\n",
       "33   LG  2019  0.258809  0.292811\n",
       "34   LT  2019  0.268657  0.292434\n",
       "35   NC  2019  0.255611  0.293007\n",
       "36   OB  2019  0.255786  0.293046\n",
       "37   SK  2019  0.233207  0.292942\n",
       "38   SS  2019  0.279376  0.292668\n",
       "39   WO  2019  0.260143  0.293207"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005385537862925611"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_pred_df['AVG'],test_pred_df['AVG_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32387279969829197"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "tmp = test_pred_df.copy()\n",
    "# tmp['half']= 0.5\n",
    "r2_y_predict = r2_score(tmp['AVG'], tmp['AVG_pred'])\n",
    "r2_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
