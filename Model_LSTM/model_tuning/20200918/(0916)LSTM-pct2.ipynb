{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"model_input_data/augment_24group_1620.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>PCT</th>\n",
       "      <th>IDX</th>\n",
       "      <th>MERGE_IDX</th>\n",
       "      <th>HEADER_NO</th>\n",
       "      <th>era</th>\n",
       "      <th>avg</th>\n",
       "      <th>vs_era</th>\n",
       "      <th>vs_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>K_9</th>\n",
       "      <th>vs_ERA</th>\n",
       "      <th>H_A</th>\n",
       "      <th>vs_K_9</th>\n",
       "      <th>vs_FIP</th>\n",
       "      <th>H_9</th>\n",
       "      <th>oSLG</th>\n",
       "      <th>vs_OPS</th>\n",
       "      <th>vs_WHIP</th>\n",
       "      <th>P2_WHIP_RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.649770</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>4.993723</td>\n",
       "      <td>0.268530</td>\n",
       "      <td>...</td>\n",
       "      <td>6.299708</td>\n",
       "      <td>5.183583</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.367167</td>\n",
       "      <td>21.210083</td>\n",
       "      <td>9.306833</td>\n",
       "      <td>0.376583</td>\n",
       "      <td>0.714208</td>\n",
       "      <td>1.588458</td>\n",
       "      <td>1.592333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.358453</td>\n",
       "      <td>0.253317</td>\n",
       "      <td>4.555222</td>\n",
       "      <td>0.298349</td>\n",
       "      <td>...</td>\n",
       "      <td>7.024500</td>\n",
       "      <td>4.564292</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.958750</td>\n",
       "      <td>25.981417</td>\n",
       "      <td>10.525375</td>\n",
       "      <td>0.411833</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>1.417625</td>\n",
       "      <td>1.958208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.715603</td>\n",
       "      <td>0.291169</td>\n",
       "      <td>4.659483</td>\n",
       "      <td>0.274605</td>\n",
       "      <td>...</td>\n",
       "      <td>6.010167</td>\n",
       "      <td>4.835125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.593083</td>\n",
       "      <td>18.368167</td>\n",
       "      <td>9.547667</td>\n",
       "      <td>0.370792</td>\n",
       "      <td>0.717458</td>\n",
       "      <td>1.526958</td>\n",
       "      <td>1.786958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.584768</td>\n",
       "      <td>0.305842</td>\n",
       "      <td>5.148837</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>...</td>\n",
       "      <td>5.717083</td>\n",
       "      <td>5.223208</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>6.863167</td>\n",
       "      <td>19.183125</td>\n",
       "      <td>10.450250</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.800958</td>\n",
       "      <td>1.615917</td>\n",
       "      <td>2.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.551402</td>\n",
       "      <td>0.297110</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.288942</td>\n",
       "      <td>...</td>\n",
       "      <td>6.221583</td>\n",
       "      <td>5.848958</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>6.665708</td>\n",
       "      <td>24.602000</td>\n",
       "      <td>10.233583</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>1.644917</td>\n",
       "      <td>2.142625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3.693396</td>\n",
       "      <td>0.263694</td>\n",
       "      <td>5.003187</td>\n",
       "      <td>0.252488</td>\n",
       "      <td>...</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>5.094958</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>6.964333</td>\n",
       "      <td>23.619042</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>0.371750</td>\n",
       "      <td>0.688375</td>\n",
       "      <td>1.373667</td>\n",
       "      <td>1.572542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3.778302</td>\n",
       "      <td>0.265997</td>\n",
       "      <td>5.151025</td>\n",
       "      <td>0.254975</td>\n",
       "      <td>...</td>\n",
       "      <td>6.218750</td>\n",
       "      <td>5.251208</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>7.011208</td>\n",
       "      <td>24.400292</td>\n",
       "      <td>8.708333</td>\n",
       "      <td>0.379583</td>\n",
       "      <td>0.696542</td>\n",
       "      <td>1.402583</td>\n",
       "      <td>1.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4.009479</td>\n",
       "      <td>0.270338</td>\n",
       "      <td>5.193950</td>\n",
       "      <td>0.261462</td>\n",
       "      <td>...</td>\n",
       "      <td>6.072917</td>\n",
       "      <td>5.292875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.886208</td>\n",
       "      <td>24.303083</td>\n",
       "      <td>9.020833</td>\n",
       "      <td>0.386208</td>\n",
       "      <td>0.709542</td>\n",
       "      <td>1.416458</td>\n",
       "      <td>1.635167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3.685714</td>\n",
       "      <td>0.265743</td>\n",
       "      <td>5.065175</td>\n",
       "      <td>0.257783</td>\n",
       "      <td>...</td>\n",
       "      <td>6.385417</td>\n",
       "      <td>5.167875</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>7.011208</td>\n",
       "      <td>24.108625</td>\n",
       "      <td>8.911458</td>\n",
       "      <td>0.388792</td>\n",
       "      <td>0.707208</td>\n",
       "      <td>1.407208</td>\n",
       "      <td>1.547667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>SS</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3.531100</td>\n",
       "      <td>0.264817</td>\n",
       "      <td>4.979324</td>\n",
       "      <td>0.254705</td>\n",
       "      <td>...</td>\n",
       "      <td>6.244792</td>\n",
       "      <td>5.084542</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>7.052875</td>\n",
       "      <td>21.807708</td>\n",
       "      <td>8.791667</td>\n",
       "      <td>0.382750</td>\n",
       "      <td>0.701167</td>\n",
       "      <td>1.402583</td>\n",
       "      <td>1.676500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4100 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_ID  YEAR       PCT  IDX  MERGE_IDX  HEADER_NO       era       avg  \\\n",
       "0      LG  2016  0.608696  777          0          0  3.649770  0.296069   \n",
       "1      LG  2016  0.500000    1          1          0  5.358453  0.253317   \n",
       "2      LG  2016  0.478261    2          2          0  4.715603  0.291169   \n",
       "3      LG  2016  0.375000    3          3          0  5.584768  0.305842   \n",
       "4      LG  2016  0.458333    4          4          0  5.551402  0.297110   \n",
       "...   ...   ...       ...  ...        ...        ...       ...       ...   \n",
       "4095   SS  2020  0.583333    1         14          3  3.693396  0.263694   \n",
       "4096   SS  2020  0.583333    1         15          3  3.778302  0.265997   \n",
       "4097   SS  2020  0.583333    1         16          3  4.009479  0.270338   \n",
       "4098   SS  2020  0.583333    1         17          3  3.685714  0.265743   \n",
       "4099   SS  2020  0.583333    1         18          3  3.531100  0.264817   \n",
       "\n",
       "        vs_era    vs_avg  ...       K_9    vs_ERA       H_A    vs_K_9  \\\n",
       "0     4.993723  0.268530  ...  6.299708  5.183583  0.625000  6.367167   \n",
       "1     4.555222  0.298349  ...  7.024500  4.564292  0.500000  7.958750   \n",
       "2     4.659483  0.274605  ...  6.010167  4.835125  0.500000  6.593083   \n",
       "3     5.148837  0.288889  ...  5.717083  5.223208  0.541667  6.863167   \n",
       "4     5.833333  0.288942  ...  6.221583  5.848958  0.416667  6.665708   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "4095  5.003187  0.252488  ...  6.343750  5.094958  0.583333  6.964333   \n",
       "4096  5.151025  0.254975  ...  6.218750  5.251208  0.541667  7.011208   \n",
       "4097  5.193950  0.261462  ...  6.072917  5.292875  0.500000  6.886208   \n",
       "4098  5.065175  0.257783  ...  6.385417  5.167875  0.458333  7.011208   \n",
       "4099  4.979324  0.254705  ...  6.244792  5.084542  0.416667  7.052875   \n",
       "\n",
       "         vs_FIP        H_9      oSLG    vs_OPS   vs_WHIP  P2_WHIP_RT  \n",
       "0     21.210083   9.306833  0.376583  0.714208  1.588458    1.592333  \n",
       "1     25.981417  10.525375  0.411833  0.777333  1.417625    1.958208  \n",
       "2     18.368167   9.547667  0.370792  0.717458  1.526958    1.786958  \n",
       "3     19.183125  10.450250  0.444000  0.800958  1.615917    2.005667  \n",
       "4     24.602000  10.233583  0.445000  0.804208  1.644917    2.142625  \n",
       "...         ...        ...       ...       ...       ...         ...  \n",
       "4095  23.619042   8.625000  0.371750  0.688375  1.373667    1.572542  \n",
       "4096  24.400292   8.708333  0.379583  0.696542  1.402583    1.575000  \n",
       "4097  24.303083   9.020833  0.386208  0.709542  1.416458    1.635167  \n",
       "4098  24.108625   8.911458  0.388792  0.707208  1.407208    1.547667  \n",
       "4099  21.807708   8.791667  0.382750  0.701167  1.402583    1.676500  \n",
       "\n",
       "[4100 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = data[[\"T_ID\",\"YEAR\",\"PCT\",\"IDX\",\"H_A\"]] #최소한의 데이터\n",
    "\n",
    "tmp = data.copy()\n",
    "\n",
    "\n",
    "tmp = tmp[tmp[\"YEAR\"]!=2020]\n",
    "tmp.head(50)\n",
    "\n",
    "train = tmp[tmp[\"IDX\"]!=777]\n",
    "test = tmp[tmp[\"IDX\"]==777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>PCT</th>\n",
       "      <th>IDX</th>\n",
       "      <th>MERGE_IDX</th>\n",
       "      <th>HEADER_NO</th>\n",
       "      <th>era</th>\n",
       "      <th>avg</th>\n",
       "      <th>vs_era</th>\n",
       "      <th>vs_avg</th>\n",
       "      <th>...</th>\n",
       "      <th>K_9</th>\n",
       "      <th>vs_ERA</th>\n",
       "      <th>H_A</th>\n",
       "      <th>vs_K_9</th>\n",
       "      <th>vs_FIP</th>\n",
       "      <th>H_9</th>\n",
       "      <th>oSLG</th>\n",
       "      <th>vs_OPS</th>\n",
       "      <th>vs_WHIP</th>\n",
       "      <th>P2_WHIP_RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.358453</td>\n",
       "      <td>0.253317</td>\n",
       "      <td>4.555222</td>\n",
       "      <td>0.298349</td>\n",
       "      <td>...</td>\n",
       "      <td>7.024500</td>\n",
       "      <td>4.564292</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.958750</td>\n",
       "      <td>25.981417</td>\n",
       "      <td>10.525375</td>\n",
       "      <td>0.411833</td>\n",
       "      <td>0.777333</td>\n",
       "      <td>1.417625</td>\n",
       "      <td>1.958208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.715603</td>\n",
       "      <td>0.291169</td>\n",
       "      <td>4.659483</td>\n",
       "      <td>0.274605</td>\n",
       "      <td>...</td>\n",
       "      <td>6.010167</td>\n",
       "      <td>4.835125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.593083</td>\n",
       "      <td>18.368167</td>\n",
       "      <td>9.547667</td>\n",
       "      <td>0.370792</td>\n",
       "      <td>0.717458</td>\n",
       "      <td>1.526958</td>\n",
       "      <td>1.786958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.584768</td>\n",
       "      <td>0.305842</td>\n",
       "      <td>5.148837</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>...</td>\n",
       "      <td>5.717083</td>\n",
       "      <td>5.223208</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>6.863167</td>\n",
       "      <td>19.183125</td>\n",
       "      <td>10.450250</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.800958</td>\n",
       "      <td>1.615917</td>\n",
       "      <td>2.005667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.551402</td>\n",
       "      <td>0.297110</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.288942</td>\n",
       "      <td>...</td>\n",
       "      <td>6.221583</td>\n",
       "      <td>5.848958</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>6.665708</td>\n",
       "      <td>24.602000</td>\n",
       "      <td>10.233583</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>1.644917</td>\n",
       "      <td>2.142625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>0.294471</td>\n",
       "      <td>5.091926</td>\n",
       "      <td>0.286756</td>\n",
       "      <td>...</td>\n",
       "      <td>6.891667</td>\n",
       "      <td>5.106250</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>6.691250</td>\n",
       "      <td>18.554625</td>\n",
       "      <td>10.194792</td>\n",
       "      <td>0.401542</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.514083</td>\n",
       "      <td>2.408083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>5.130841</td>\n",
       "      <td>0.302817</td>\n",
       "      <td>5.255895</td>\n",
       "      <td>0.288942</td>\n",
       "      <td>...</td>\n",
       "      <td>6.881250</td>\n",
       "      <td>5.304167</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>6.456875</td>\n",
       "      <td>19.565083</td>\n",
       "      <td>10.298958</td>\n",
       "      <td>0.400958</td>\n",
       "      <td>0.750708</td>\n",
       "      <td>1.560375</td>\n",
       "      <td>2.347458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>5.299065</td>\n",
       "      <td>0.285024</td>\n",
       "      <td>4.702962</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042708</td>\n",
       "      <td>4.842708</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>6.630958</td>\n",
       "      <td>17.568083</td>\n",
       "      <td>10.106250</td>\n",
       "      <td>0.392250</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>1.500458</td>\n",
       "      <td>1.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.304447</td>\n",
       "      <td>4.852535</td>\n",
       "      <td>0.280516</td>\n",
       "      <td>...</td>\n",
       "      <td>5.642875</td>\n",
       "      <td>4.965625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.700292</td>\n",
       "      <td>19.344333</td>\n",
       "      <td>10.058333</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.781125</td>\n",
       "      <td>1.605375</td>\n",
       "      <td>1.923625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5.845794</td>\n",
       "      <td>0.295481</td>\n",
       "      <td>5.682028</td>\n",
       "      <td>0.300469</td>\n",
       "      <td>...</td>\n",
       "      <td>6.263250</td>\n",
       "      <td>5.671875</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>6.389667</td>\n",
       "      <td>24.663333</td>\n",
       "      <td>10.775250</td>\n",
       "      <td>0.461042</td>\n",
       "      <td>0.832167</td>\n",
       "      <td>1.619458</td>\n",
       "      <td>2.225958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LG</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>5.075829</td>\n",
       "      <td>0.297006</td>\n",
       "      <td>5.331219</td>\n",
       "      <td>0.281896</td>\n",
       "      <td>...</td>\n",
       "      <td>7.006250</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>6.800625</td>\n",
       "      <td>18.780333</td>\n",
       "      <td>9.986458</td>\n",
       "      <td>0.388375</td>\n",
       "      <td>0.733167</td>\n",
       "      <td>1.548792</td>\n",
       "      <td>2.344000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   T_ID  YEAR       PCT  IDX  MERGE_IDX  HEADER_NO       era       avg  \\\n",
       "1    LG  2016  0.500000    1          1          0  5.358453  0.253317   \n",
       "2    LG  2016  0.478261    2          2          0  4.715603  0.291169   \n",
       "3    LG  2016  0.375000    3          3          0  5.584768  0.305842   \n",
       "4    LG  2016  0.458333    4          4          0  5.551402  0.297110   \n",
       "5    LG  2016  0.583333    5          5          0  5.400000  0.294471   \n",
       "..  ...   ...       ...  ...        ...        ...       ...       ...   \n",
       "93   LG  2016  0.625000    4         93          0  5.130841  0.302817   \n",
       "94   LG  2016  0.478261    1         94          0  5.299065  0.285024   \n",
       "95   LG  2016  0.375000    2         95          0  5.333333  0.304447   \n",
       "96   LG  2016  0.416667    3         96          0  5.845794  0.295481   \n",
       "97   LG  2016  0.625000    4         97          0  5.075829  0.297006   \n",
       "\n",
       "      vs_era    vs_avg  ...       K_9    vs_ERA       H_A    vs_K_9  \\\n",
       "1   4.555222  0.298349  ...  7.024500  4.564292  0.500000  7.958750   \n",
       "2   4.659483  0.274605  ...  6.010167  4.835125  0.500000  6.593083   \n",
       "3   5.148837  0.288889  ...  5.717083  5.223208  0.541667  6.863167   \n",
       "4   5.833333  0.288942  ...  6.221583  5.848958  0.416667  6.665708   \n",
       "5   5.091926  0.286756  ...  6.891667  5.106250  0.416667  6.691250   \n",
       "..       ...       ...  ...       ...       ...       ...       ...   \n",
       "93  5.255895  0.288942  ...  6.881250  5.304167  0.458333  6.456875   \n",
       "94  4.702962  0.285714  ...  6.042708  4.842708  0.541667  6.630958   \n",
       "95  4.852535  0.280516  ...  5.642875  4.965625  0.500000  6.700292   \n",
       "96  5.682028  0.300469  ...  6.263250  5.671875  0.416667  6.389667   \n",
       "97  5.331219  0.281896  ...  7.006250  5.366667  0.458333  6.800625   \n",
       "\n",
       "       vs_FIP        H_9      oSLG    vs_OPS   vs_WHIP  P2_WHIP_RT  \n",
       "1   25.981417  10.525375  0.411833  0.777333  1.417625    1.958208  \n",
       "2   18.368167   9.547667  0.370792  0.717458  1.526958    1.786958  \n",
       "3   19.183125  10.450250  0.444000  0.800958  1.615917    2.005667  \n",
       "4   24.602000  10.233583  0.445000  0.804208  1.644917    2.142625  \n",
       "5   18.554625  10.194792  0.401542  0.757000  1.514083    2.408083  \n",
       "..        ...        ...       ...       ...       ...         ...  \n",
       "93  19.565083  10.298958  0.400958  0.750708  1.560375    2.347458  \n",
       "94  17.568083  10.106250  0.392250  0.746875  1.500458    1.931500  \n",
       "95  19.344333  10.058333  0.430292  0.781125  1.605375    1.923625  \n",
       "96  24.663333  10.775250  0.461042  0.832167  1.619458    2.225958  \n",
       "97  18.780333   9.986458  0.388375  0.733167  1.548792    2.344000  \n",
       "\n",
       "[97 rows x 72 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttmp = train[(train[\"T_ID\"]=='LG')]\n",
    "ttmp = ttmp[(ttmp[\"YEAR\"]==2016)]\n",
    "ttmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = pd.DataFrame([])\n",
    "\n",
    "for i in range(1,3):\n",
    "    for c in list(set(list(ttmp.columns))-set(['T_ID','YEAR'])):\n",
    "        aaa.loc[:,'shift_{}_{}'.format(c,i)] = ttmp.loc[:,c].shift(i)\n",
    "        \n",
    "aaa.loc[:,[\"IDX\",\"MERGE_IDX\",\"PCT\"]] = ttmp.loc[:,[\"IDX\",\"MERGE_IDX\",\"PCT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttmp = aaa.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttmp.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttmp_idx = list(ttmp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_idx = []\n",
    "for i in ttmp_idx:\n",
    "    idx_num = ttmp.loc[i,'IDX']\n",
    "    if idx_num < ttmp.loc[i,'shift_IDX_1'] or idx_num < ttmp.loc[i,'shift_IDX_2']:\n",
    "        drop_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_data = ttmp.drop(drop_idx).reset_index(drop = True)\n",
    "\n",
    "# shift_data = pd.concat([shift_data, pd.get_dummies(data.T_ID)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_shift_lst= []\n",
    "for i in list(shift_data.columns):\n",
    "    if 'shift' not in i:\n",
    "        no_shift_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = shift_data.drop(no_shift_lst,axis = 1)\n",
    "y_train = shift_data[[\"PCT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 140), (49, 1))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel_col = list(test.columns)\n",
    "\n",
    "tmp5 = data[(data[\"IDX\"]==5)&(data[\"T_ID\"]=='LG')][sel_col]\n",
    "tmp4 = data[(data[\"IDX\"]==4) & (data[\"MERGE_IDX\"]==4)&(data[\"T_ID\"]=='LG')][sel_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat([test[test[\"T_ID\"]=='LG'],tmp5,tmp4], axis = 0).sort_values(by=[\"YEAR\",\"IDX\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df[\"YEAR\"]==2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb = pd.DataFrame([])\n",
    "\n",
    "for i in range(1,3):\n",
    "    for c in list(set(list(test_df.columns))-set(['T_ID','YEAR'])):\n",
    "        bbb.loc[:,'shift_{}_{}'.format(c,i)] = test_df.loc[:,c].shift(i)\n",
    "        \n",
    "bbb.loc[:,[\"IDX\",\"MERGE_IDX\",\"PCT\"]] = test_df.loc[:,[\"IDX\",\"MERGE_IDX\",\"PCT\"]]\n",
    "\n",
    "\n",
    "# for c in list(set(list(test_df.columns))-set(['T_ID','YEAR'])):\n",
    "#     for i in range(1,3):\n",
    "#         test_df.loc[:,'shift_{}_{}'.format(c,i)] = test_df.loc[:,c].shift(i)\n",
    "\n",
    "# for i in range(1,3):\n",
    "#     test_df.loc[:,'shift_{}_{}'.format('PCT',i)] = test_df.loc[:,'PCT'].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = bbb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tmp = test_df[test_df[\"IDX\"]==777]\n",
    "X_test = test_tmp.drop(no_shift_lst,axis = 1)\n",
    "y_test = test_tmp[[\"PCT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift_TA_1</th>\n",
       "      <th>shift_vs_DER_1</th>\n",
       "      <th>shift_vs_AVG_1</th>\n",
       "      <th>shift_HEADER_NO_1</th>\n",
       "      <th>shift_P_WHIP_RT_1</th>\n",
       "      <th>shift_vs_H_9_1</th>\n",
       "      <th>shift_vs_oOBP_1</th>\n",
       "      <th>shift_WHIP_1</th>\n",
       "      <th>shift_vs_ISO_1</th>\n",
       "      <th>shift_era_1</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_vs_OBP_2</th>\n",
       "      <th>shift_oSLG_2</th>\n",
       "      <th>shift_vs_K_9_2</th>\n",
       "      <th>shift_vs_BB_9_2</th>\n",
       "      <th>shift_K_9_2</th>\n",
       "      <th>shift_vs_WHIP_2</th>\n",
       "      <th>shift_RC_2</th>\n",
       "      <th>shift_ERA_2</th>\n",
       "      <th>shift_avg_2</th>\n",
       "      <th>shift_vs_BA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739</td>\n",
       "      <td>0.663083</td>\n",
       "      <td>0.28075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.950333</td>\n",
       "      <td>10.506667</td>\n",
       "      <td>0.339542</td>\n",
       "      <td>1.548125</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365458</td>\n",
       "      <td>0.445</td>\n",
       "      <td>6.665708</td>\n",
       "      <td>4.143</td>\n",
       "      <td>6.221583</td>\n",
       "      <td>1.644917</td>\n",
       "      <td>1.201167</td>\n",
       "      <td>5.592792</td>\n",
       "      <td>0.29711</td>\n",
       "      <td>0.280625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shift_TA_1  shift_vs_DER_1  shift_vs_AVG_1  shift_HEADER_NO_1  \\\n",
       "0       0.739        0.663083         0.28075                0.0   \n",
       "\n",
       "   shift_P_WHIP_RT_1  shift_vs_H_9_1  shift_vs_oOBP_1  shift_WHIP_1  \\\n",
       "0           1.950333       10.506667         0.339542      1.548125   \n",
       "\n",
       "   shift_vs_ISO_1  shift_era_1  ...  shift_vs_OBP_2  shift_oSLG_2  \\\n",
       "0        0.116375          5.4  ...        0.365458         0.445   \n",
       "\n",
       "   shift_vs_K_9_2  shift_vs_BB_9_2  shift_K_9_2  shift_vs_WHIP_2  shift_RC_2  \\\n",
       "0        6.665708            4.143     6.221583         1.644917    1.201167   \n",
       "\n",
       "   shift_ERA_2  shift_avg_2  shift_vs_BA_2  \n",
       "0     5.592792      0.29711       0.280625  \n",
       "\n",
       "[1 rows x 140 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = X_train.values\n",
    "y_train_v = y_train.values\n",
    "\n",
    "X_test_v = X_test.values\n",
    "y_test_v = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 140), (49, 1), (1, 140), (1, 1))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_v.shape, y_train_v.shape, X_test_v.shape, y_test_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train_v.reshape(X_train_v.shape[0], 2,70)\n",
    "X_test_t = X_test_v.reshape(X_test_v.shape[0], 2,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 2, 70),\n",
       " array([[7.54333333e-01, 6.69541667e-01, 2.68791667e-01, 0.00000000e+00,\n",
       "         2.35179167e+00, 1.03035833e+01, 3.39291667e-01, 1.52133333e+00,\n",
       "         9.83750000e-02, 4.71560322e+00, 2.00141667e+00, 9.54766667e+00,\n",
       "         5.31250000e-01, 3.55625000e-01, 9.73000000e+02, 4.07500000e-01,\n",
       "         7.58833333e-01, 4.58333333e-01, 4.03208333e-01, 2.49500000e-01,\n",
       "         2.96458333e-01, 2.86125000e-01, 8.45500000e-01, 4.65948330e+00,\n",
       "         5.00000000e-01, 7.11250000e-01, 2.74605103e-01, 2.86125000e-01,\n",
       "         6.96458333e-01, 3.36875000e-01, 2.79666667e-01, 4.99908333e+00,\n",
       "         5.00000000e-01, 4.14429167e+00, 4.83512500e+00, 7.17458333e-01,\n",
       "         2.93666667e-01, 1.83681667e+01, 3.76750000e-01, 1.79695833e+00,\n",
       "         3.67166667e-01, 2.71625000e-01, 1.89143750e+01, 7.15333333e-01,\n",
       "         5.89875000e-01, 1.97179167e+00, 3.24333333e-01, 4.78260870e-01,\n",
       "         2.00000000e+00, 6.85916667e-01, 2.88875000e-01, 9.73000000e+02,\n",
       "         1.17083333e-01, 4.60900000e+00, 2.60833333e-01, 2.00000000e+00,\n",
       "         1.78695833e+00, 1.62683333e+00, 5.00000000e-01, 3.72791667e-01,\n",
       "         3.50291667e-01, 3.70791667e-01, 6.59308333e+00, 3.43966667e+00,\n",
       "         6.01016667e+00, 1.52695833e+00, 8.25416667e-01, 4.84087500e+00,\n",
       "         2.91169451e-01, 2.68791667e-01],\n",
       "        [7.07125000e-01, 7.04083333e-01, 2.89208333e-01, 0.00000000e+00,\n",
       "         2.09812500e+00, 8.70520833e+00, 3.12583333e-01, 1.59525000e+00,\n",
       "         1.25750000e-01, 5.35845329e+00, 1.91862500e+00, 1.05253750e+01,\n",
       "         8.44791667e-01, 3.25583333e-01, 9.72833333e+02, 3.79666667e-01,\n",
       "         6.99750000e-01, 5.00000000e-01, 3.74166667e-01, 2.66833333e-01,\n",
       "         3.12041667e-01, 2.45625000e-01, 8.70291667e-01, 4.55522171e+00,\n",
       "         5.00000000e-01, 6.87916667e-01, 2.98349057e-01, 2.45625000e-01,\n",
       "         6.59333333e-01, 3.49208333e-01, 2.16875000e-01, 4.71558333e+00,\n",
       "         5.00000000e-01, 3.83245833e+00, 4.56429167e+00, 7.77333333e-01,\n",
       "         3.15791667e-01, 2.59814167e+01, 3.57375000e-01, 1.41950000e+00,\n",
       "         4.14958333e-01, 2.86875000e-01, 2.07307083e+01, 7.67708333e-01,\n",
       "         1.13225000e+00, 1.79175000e+00, 3.03000000e-01, 5.00000000e-01,\n",
       "         1.00000000e+00, 7.52291667e-01, 2.49250000e-01, 9.72833333e+02,\n",
       "         1.28541667e-01, 5.26025000e+00, 2.40041667e-01, 1.00000000e+00,\n",
       "         1.95820833e+00, 1.54479167e+00, 5.00000000e-01, 3.89000000e-01,\n",
       "         3.62375000e-01, 4.11833333e-01, 7.95875000e+00, 4.05300000e+00,\n",
       "         7.02450000e+00, 1.41762500e+00, 6.56958333e-01, 5.44512500e+00,\n",
       "         2.53317250e-01, 2.89208333e-01]]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape, X_train_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100)               68400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 68,501\n",
      "Trainable params: 68,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() \n",
    "\n",
    "model = Sequential()\n",
    "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.add(LSTM(100,input_shape = (2,70))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49 samples\n",
      "Epoch 1/100\n",
      " 1/49 [..............................] - ETA: 11sWARNING:tensorflow:Early stopping conditioned on metric `loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_4331]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-10de81e76a23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n\u001b[1;32m----> 5\u001b[1;33m           batch_size=1, verbose=1, callbacks=[early_stop])\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mC:\\Users\\julia\\tf_jupyter\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_4331]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "\n",
    "hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "          batch_size=1, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist1.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist1.history['mae'], 'b', label='train mae')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('mae')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479246</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred         y\n",
       "0  0.479246  0.608696"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"y_pred\":y_pred.reshape(-1), \n",
    "              \"y\":y_test_v.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47924638]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1294492742289668"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y_test_v, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LG, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.479246</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred         y\n",
       "0  0.479246  0.608696"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"y_pred\":y_pred.reshape(-1), \n",
    "              \"y\":y_test_v.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47924638]], dtype=float32)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1294492742289668"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y_test_v, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LG, 모든시즌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491760</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557402</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.565112</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501496</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred         y\n",
       "0  0.491760  0.608696\n",
       "1  0.557402  0.434783\n",
       "2  0.565112  0.416667\n",
       "3  0.501496  0.541667"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"y_pred\":y_pred.reshape(-1), \n",
    "              \"y\":y_test_v.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47158092],\n",
       "       [0.5409802 ],\n",
       "       [0.53747755],\n",
       "       [0.48298073]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1096787254758451"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y_test_v, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"model_input_data/PCT_train_X.csv\")\n",
    "y_train = pd.read_csv(\"model_input_data/PCT_test_X.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"model_input_data/PCT_train_y.csv\")\n",
    "y_test = pd.read_csv(\"model_input_data/PCT_test_y.csv\")\n",
    "\n",
    "X_train = X_train[(X_train[\"shift_YEAR\"] == 2019)&(X_train[\"LG\"] == 1)]\n",
    "X_test = X_test[(X_test[\"shift_YEAR\"] == 2019)&(X_test[\"LG\"]==1)]\n",
    "\n",
    "# X_train = X_train[(X_train[\"LG\"] == 1)]\n",
    "# X_test = X_test[(X_test[\"LG\"]==1)]\n",
    "\n",
    "\n",
    "sel_col = ['shift_H_A',\"shift_era\", \"shift_avg\",\"shift_PCT\",\"shift_SLG\"]\n",
    "\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "y_train = y_train.iloc[train_index,:]\n",
    "y_test = y_test.iloc[test_index,:]\n",
    "\n",
    "# X_train = X_train[sel_col].reset_index(drop = True)\n",
    "# X_test = X_test[sel_col].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_v = X_train.values\n",
    "y_train_v = y_train.values\n",
    "\n",
    "X_test_v = X_test.values\n",
    "y_test_v = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train_v.reshape(X_train_v.shape[0], X_train_v.shape[1],1)\n",
    "X_test_t = X_test_v.reshape(X_test_v.shape[0], X_train_v.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 79, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [3.37962500e+00],\n",
       "       [3.81583333e-01],\n",
       "       [2.01900000e+03],\n",
       "       [3.53087500e+00],\n",
       "       [2.70409301e+00],\n",
       "       [4.23875000e-01],\n",
       "       [1.64387500e+00],\n",
       "       [9.81291667e+02],\n",
       "       [2.59416667e-01],\n",
       "       [5.41666667e-01],\n",
       "       [6.04750000e-01],\n",
       "       [1.30470833e+00],\n",
       "       [8.28850000e+00],\n",
       "       [2.74673008e-01],\n",
       "       [2.59125000e-01],\n",
       "       [2.44500000e-01],\n",
       "       [2.66586248e-01],\n",
       "       [2.99666667e-01],\n",
       "       [7.18708333e-01],\n",
       "       [4.58333333e-01],\n",
       "       [3.48784725e+00],\n",
       "       [4.16666667e-01],\n",
       "       [3.49750000e-01],\n",
       "       [4.67983333e+00],\n",
       "       [2.15458333e-01],\n",
       "       [2.98125000e-01],\n",
       "       [7.18041667e-01],\n",
       "       [7.66666667e-01],\n",
       "       [3.38750000e-01],\n",
       "       [1.54458333e+00],\n",
       "       [3.37962500e+00],\n",
       "       [5.93750000e-01],\n",
       "       [7.91108333e+00],\n",
       "       [1.28554167e+00],\n",
       "       [2.47791667e-01],\n",
       "       [9.81291667e+02],\n",
       "       [3.24500000e-01],\n",
       "       [7.59833333e-01],\n",
       "       [1.75644583e+01],\n",
       "       [2.74487500e+00],\n",
       "       [2.09125000e-01],\n",
       "       [1.55320833e+00],\n",
       "       [3.40416667e-01],\n",
       "       [3.38083333e-01],\n",
       "       [5.41666667e-01],\n",
       "       [1.22166667e-01],\n",
       "       [1.11391667e+00],\n",
       "       [2.76041667e-01],\n",
       "       [1.15558333e+00],\n",
       "       [7.02079167e+00],\n",
       "       [1.29641667e+00],\n",
       "       [7.31916667e-01],\n",
       "       [2.42125000e-01],\n",
       "       [6.83533333e+00],\n",
       "       [3.77458333e-01],\n",
       "       [5.08316667e+00],\n",
       "       [2.59416667e-01],\n",
       "       [1.51170000e+01],\n",
       "       [7.64291667e-01],\n",
       "       [2.69916667e-01],\n",
       "       [5.83333333e-01],\n",
       "       [3.81375000e-01],\n",
       "       [0.00000000e+00],\n",
       "       [2.69916667e-01],\n",
       "       [3.67666667e-01],\n",
       "       [1.53958333e-01],\n",
       "       [7.60166667e-01],\n",
       "       [7.20333333e-01],\n",
       "       [7.31666667e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 40)                6720      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 6,761\n",
      "Trainable params: 6,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() \n",
    "\n",
    "model = Sequential()\n",
    "optimizer = RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "model.add(LSTM(40,input_shape = (X_train_v.shape[1],1))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer,metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 292 samples\n",
      "Epoch 1/100\n",
      "292/292 [==============================] - 5s 17ms/sample - loss: 0.0266 - mae: 0.1281\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0146 - mae: 0.0979\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0147 - mae: 0.0970\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0146 - mae: 0.0963\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0145 - mae: 0.0966\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0145 - mae: 0.0962\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0143 - mae: 0.0963\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 3s 10ms/sample - loss: 0.0142 - mae: 0.0960\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 3s 9ms/sample - loss: 0.0145 - mae: 0.0958\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 3s 10ms/sample - loss: 0.0142 - mae: 0.0959\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 3s 11ms/sample - loss: 0.0142 - mae: 0.0950\n",
      "Epoch 12/100\n",
      "292/292 [==============================] - 3s 12ms/sample - loss: 0.0140 - mae: 0.09480s - loss: 0.0140 - mae: 0.09 - ETA: 0s - loss: 0.013\n",
      "Epoch 13/100\n",
      "292/292 [==============================] - 3s 10ms/sample - loss: 0.0142 - mae: 0.0958\n",
      "Epoch 14/100\n",
      "292/292 [==============================] - 3s 12ms/sample - loss: 0.0142 - mae: 0.09560s - loss: 0.0131 - mae: 0.0 - ETA: 0s - loss: 0\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', mode = 'min',patience=2, verbose=1)\n",
    "\n",
    "\n",
    "hist1 = model.fit(X_train_t, y_train_v, epochs=100,\n",
    "          batch_size=1, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist1.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist1.history['mae'], 'b', label='train mae')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('mae')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516332</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.487553</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.524546</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.516562</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.494340</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_pred         y\n",
       "0  0.516332  0.608696\n",
       "1  0.487553  0.434783\n",
       "2  0.524546  0.416667\n",
       "3  0.516562  0.541667\n",
       "4  0.494340  0.391304"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"y_pred\":y_pred.reshape(-1), \n",
    "              \"y\":y_test_v.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565],\n",
       "       [0.43478261],\n",
       "       [0.41666667],\n",
       "       [0.54166667],\n",
       "       [0.39130435]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08270456663119312"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y_test_v, y_pred.astype(np.float64).reshape(5,1)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36_tf20",
   "language": "python",
   "name": "tf_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
